<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>机器学习常用函数 - 李小肥的YY</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="李小肥的YY" property="og:site_name">
  
    <meta content="机器学习常用函数" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="一些常用的数据分析处理和数学建模的工具函数" property="og:description">
  
  
    <meta content="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" property="og:url">
  
  
    <meta content="2018-11-11T05:00:00+08:00" property="article:published_time">
    <meta content="http://localhost:4000/about/" property="article:author">
  
  
    <meta content="http://localhost:4000/assets/img/math.jpg" property="og:image">
  
  
    
  
  
    
    <meta content="Pandas" property="article:tag">
    
    <meta content="Sklearn" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@">
  
    <meta name="twitter:title" content="机器学习常用函数">
  
  
    <meta name="twitter:url" content="http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/">
  
  
    <meta name="twitter:description" content="一些常用的数据分析处理和数学建模的工具函数">
  
  
    <meta name="twitter:image:src" content="http://localhost:4000/assets/img/math.jpg">
  

	<meta name="description" content="一些常用的数据分析处理和数学建模的工具函数">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<link rel="shortcut icon" href="/assets/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="/assets/img/favicon/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicon/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicon/apple-touch-icon-144x144.png">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700|Lato:300,400,700&display=swap" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/yy.jpg" alt="李小肥的YY"></a>
      </div>
      <div class="author-name">李小肥的YY</div>
      <p>爱好机器学习，深度学习，NLP和CV。</p>
    </div>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact me</h3>
      <ul>
        
          <li><a href="https://twitter.com/artemsheludko_" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        
          <li><a href="https://facebook.com/" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/yy2lyx/" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
          <li class="linkedin"><a href="https://in.linkedin.com/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li>
        
        
          <li class="email"><a href="mailto:1282442333@qq.com# add your Email address"><i class="fa fa-envelope-o"></i></a></li>
        
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
      <p>2020 &copy; 李小肥的YY</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->
<div class="content-box clearfix">
  <article class="article-page">
  <div class="page-content">
    
    <div class="page-cover-image">
      <figure>
        <img class="page-image" src=/assets/img/math.jpg alt="机器学习常用函数">
        
      </figure>
    </div> <!-- End Page Cover Image -->
    
    <div class="wrap-content">
      <header class="header-page">
        <h1 class="page-title">机器学习常用函数</h1>
        <div class="page-date"><span>2018, Nov 11&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
      </header>
      <h3 id="一数据处理工具pandas和numpy">一.数据处理工具pandas和numpy</h3>
<h4 id="11-pandas读取数据">1.1 pandas读取数据</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data.csv"</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">encoding</span> <span class="o">=</span> <span class="s">"utf-8"</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_tabel</span><span class="p">(</span><span class="s">"data.txt"</span><span class="p">,</span><span class="n">sep</span> <span class="o">=</span> <span class="s">","</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="12-numpyrandom-生成数据的用法">1.2 numpy.random 生成数据的用法</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">numpy</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>  <span class="o">==&gt;</span><span class="n">生成4</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="n">的矩阵</span><span class="err">，</span><span class="n">其中元素在</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="err">，</span><span class="nb">float</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>  <span class="o">==&gt;</span><span class="n">生成4</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="mi">3</span><span class="n">的矩阵</span><span class="err">，</span><span class="n">元素是标准正态分布</span><span class="err">（</span><span class="n">以0为均值</span><span class="err">、</span><span class="n">以1为标准差的正态分布</span><span class="err">，</span><span class="n">记为N</span><span class="err">（</span><span class="mi">0</span><span class="err">，</span><span class="mi">1</span><span class="err">）），</span><span class="nb">float</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>  <span class="o">==&gt;</span><span class="n">生成一个2</span><span class="o">*</span><span class="mi">2</span><span class="n">的矩阵</span><span class="err">，</span><span class="n">元素值在</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span><span class="n">随机整数</span><span class="err">，</span><span class="nb">int</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random_sample</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>  <span class="o">==&gt;</span><span class="n">生成一个2</span><span class="o">*</span><span class="mi">2</span><span class="n">的矩阵</span><span class="err">，</span><span class="n">元素是</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="nb">float</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1676</span><span class="p">)</span> <span class="o">==&gt;</span><span class="n">设置种子数</span><span class="err">，</span><span class="n">每次生成的随机数相同</span>
</code></pre></div></div>

<h4 id="13-pandas_profiling">1.3 pandas_profiling</h4>
<p>用于简单快速查看数据分布和得到数据报告。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas_profiling</span>
<span class="n">pfr</span> <span class="o">=</span> <span class="n">pandas_profiling</span><span class="p">.</span><span class="n">ProfileReport</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">pfr</span><span class="p">.</span><span class="n">to_file</span><span class="p">(</span><span class="s">"./example.html"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="14-pandas去掉重复项-dfdrop_duplicates">1.4 pandas去掉重复项 df.drop_duplicates()</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">duplicated</span><span class="p">()].</span><span class="n">shape</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<h4 id="15-pandas中loc和iloc区别">1.5 pandas中loc和iloc区别</h4>

<ul>
  <li>
    <p><strong>loc</strong>利用index的名称（<strong>这里可以是index和行号不一致</strong>），来获取想要的行（或列）。（名称导向的这个特点，使得df[df.loc[‘col_name’] == ‘condition’, ‘col_name’] = value_1成立。
具体的实际应用，可参考 代码案例 一步实现EXCEL的合并数据、数据筛选、数据透视功能。</p>
  </li>
  <li>
    <p><strong>iloc</strong>利用index的具体位置（所以它<strong>只能是整数型参数</strong>，<strong>行号</strong>），来获取想要的<strong>行</strong>（或<strong>列</strong>）。</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 这里loc就可以直接用自己写的索引来构成
</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'C'</span><span class="p">:</span><span class="s">'6'</span><span class="p">,</span> <span class="s">'3'</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> 

<span class="c1"># 利用iloc抽取指定位置（所在的行整数值）的索引所构成的新的dataframe
</span><span class="n">new_dataframe</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index_list</span><span class="p">,:]</span>
</code></pre></div></div>

<p>####1.6 找到Nan值——np.isnan()</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nan_np_list</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">np_data</span><span class="p">))</span>
</code></pre></div></div>

<p>####1.7 哑变量生成——pd.get_dummies()</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dummy_device_type</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data_org</span><span class="p">[</span><span class="s">'platform'</span><span class="p">],</span><span class="n">prefix</span><span class="o">=</span><span class="s">'device_type'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="18-计算特征之间的相关系数">1.8 计算特征之间的相关系数</h4>

<p>自变量之间相关系数较大的话，需要考虑共线性的问题，共线性会导致模型出现开式解，降低模型的稳定性。</p>

<p>常见方法有<strong>皮尔森相关系数</strong>和<strong>斯皮尔曼相关系数</strong>。两个系数都是介于-1和1之间，-1表示完全负相关，1表示完全正相关，0表示完全不相关。</p>

<p>使用皮尔森相关系数有局限：要求数据是成对的从正态分布中取得的。而斯皮尔曼相关系数是一种秩相关系数，不受数据分布的影响，它通过对变量排序，以排序后两个变量的秩次差来计算相关系数。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pearson</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span> <span class="c1"># 适用于都是连续性变量
</span><span class="n">spearman</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">corr</span><span class="p">(</span><span class="s">'spearman'</span><span class="p">)</span> <span class="c1"># 适用于离散和连续变量
</span></code></pre></div></div>

<h4 id="19-dataframe的拼接">1.9 dataframe的拼接</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_all_row</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span><span class="n">df2</span><span class="p">])</span>  <span class="c1">#等价于 df1.append(df2)，纵着拼接
</span>
<span class="c1">#等价于 merge(df1,df2,left_index=True,right_index=True,how='outer')
</span><span class="n">df_all_col</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span><span class="n">df2</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 横着拼接
</span></code></pre></div></div>

<h4 id="110--groupby的使用">1.10  groupby的使用</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'A'</span><span class="p">:</span> <span class="p">[</span><span class="s">'a'</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'c'</span><span class="p">,</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'c'</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'c'</span><span class="p">],</span> 
                   <span class="s">'B'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> 
                   <span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mi">102</span><span class="p">,</span> <span class="mi">98</span><span class="p">,</span> <span class="mi">107</span><span class="p">,</span> <span class="mi">104</span><span class="p">,</span> <span class="mi">115</span><span class="p">,</span> <span class="mi">87</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">123</span><span class="p">]})</span>
<span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'A'</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
<span class="o">==&gt;</span>     
<span class="n">A</span>   <span class="n">B</span>       <span class="n">C</span>                 
<span class="n">a</span>  <span class="mf">2.0</span>  <span class="mf">108.000000</span>
<span class="n">b</span>  <span class="mf">6.5</span>   <span class="mf">95.000000</span>
<span class="n">c</span>  <span class="mf">5.0</span>  <span class="mf">104.666667</span>
</code></pre></div></div>

<h4 id="111--seriesapply">1.11  Series.apply</h4>

<p>该函数用于对该series的所有元素进行处理生成一个新的series。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_series</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]).</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="s">"""这里是函数中带2个参数的"""</span>
<span class="k">def</span> <span class="nf">subtract_custom_value</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">custom_value</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">custom_value</span>
<span class="n">new_series_2</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">subtract_custom_value</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,))</span>
</code></pre></div></div>

<h4 id="112--series可以直接用于2个列相加减">1.12  Series可以直接用于2个列相加减</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">([</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">diff_series</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span>
</code></pre></div></div>

<h3 id="二绘图查看数据分布seaborn和matplotlib">二.绘图查看数据分布——seaborn和matplotlib</h3>
<h4 id="21-频数分布直方图">2.1 频数分布直方图</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_bar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">color</span><span class="p">,</span><span class="n">title</span><span class="p">,</span><span class="n">width</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">width</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="n">color</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="s">'%.2f%%'</span> <span class="o">%</span> 			          <span class="p">((</span><span class="n">yy</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nb">sum</span><span class="p">())</span><span class="o">*</span><span class="mi">100</span><span class="p">)),</span> <span class="n">ha</span><span class="o">=</span><span class="s">'center'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Hour'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Trade-Frequence'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">15</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>

<span class="c1"># the histogram of the data
</span><span class="n">n</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">patches</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s">'g'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Smarts'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Probability'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Histogram of IQ'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="p">.</span><span class="mi">025</span><span class="p">,</span> <span class="s">r'$\mu=100,\ \sigma=15$'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">40</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjei4iy6bdj30hs0dcq3t.jpg" alt="" /></p>

<h4 id="22-散点图">2.2 散点图</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="23-直线图">2.3 直线图</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="24-双变量分布图">2.4 双变量分布图</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">two_dims_draw_relationship</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">xlabel</span><span class="p">,</span><span class="n">ylabel</span><span class="p">):</span>
    <span class="c1"># 双变量分布 x,ylabel是字符串，df必须是双维度的dataframe
</span>    <span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">color_codes</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">xlabel</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">"kde"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>
    <span class="n">g</span><span class="p">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">"m"</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">"+"</span><span class="p">)</span>
    <span class="n">g</span><span class="p">.</span><span class="n">ax_joint</span><span class="p">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_alpha</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 画背景网格线
</span>    <span class="n">g</span><span class="p">.</span><span class="n">set_axis_labels</span><span class="p">(</span><span class="s">"${}$"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">xlabel</span><span class="p">),</span> <span class="s">"${}$"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ylabel</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjei4tn70wj30go0goaav.jpg" alt="" /></p>

<h4 id="25-多变量两两之间的分布图">2.5 多变量两两之间的分布图</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">all_two_feature_distribution</span><span class="p">(</span><span class="n">df</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s">'iris'</span><span class="p">)):</span>
    <span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">"ticks"</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"species"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gjei41be5cj30v40qutd8.jpg" alt="" /></p>

<h4 id="26-热度图">2.6 热度图</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_h</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores_h</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">scores_h</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">]</span>
<span class="n">scores_h</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">scores_h</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">xticklabels</span><span class="o">=</span><span class="n">cols_all_features</span><span class="p">,</span>
                 <span class="n">yticklabels</span><span class="o">=</span><span class="n">cols_all_features</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'.2f'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"N_cluster"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"linkages"</span><span class="p">)</span>
<span class="c1"># 必须先savefig，之后再show，就不会出现保存时白色图片了
</span><span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">"h.jpg"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="三机器学习包sklearn">三.机器学习包sklearn</h3>
<h4 id="31-划分数据集">3.1 划分数据集</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="p">(</span><span class="n">trainX</span><span class="p">,</span><span class="n">testX</span><span class="p">,</span><span class="n">trainY</span><span class="p">,</span><span class="n">testY</span><span class="p">)</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="32-特征标准化">3.2 特征标准化</h4>
<h5 id="321-第一种">3.2.1 第一种</h5>
<p>使用scale模块直接计算标准化，将标准化的array放在x_scale中，同时可以查看均值和标准差，但是该方式的一个不足是当存在新的样本到来时，无法利用已有的模块直接复用，需要利用mean和std自己计算。</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_scale</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">scale</span><span class="p">(</span><span class="n">DatMat</span><span class="p">)</span>  
<span class="n">x_scale</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x_scale</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>
<h5 id="322-第二种">3.2.2 第二种</h5>
<p>第二种：使用StandardScaler模块计算标准化，可以利用训练集数据建立一个转化的类，类似于实现将mean和std存储在该类中，将数据输入，就可以直接求出结果。</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">datingDatMat</span><span class="p">)</span>
<span class="n">datingDatMat</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">datingDatMat</span><span class="p">)</span>
<span class="n">new_date</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">new_date_std</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">new_date</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>
<p>这里的scaler更象是扮演一个计算器的角色，本身并不存储数据。</p>

<h4 id="33-交叉验证查验模型稳定性">3.3 交叉验证——查验模型稳定性</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
 <span class="n">model_stability</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                              <span class="n">trainX</span><span class="p">,</span><span class="n">trainY</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">"accuracy"</span><span class="p">)</span>
<span class="n">mean_score_model</span> <span class="o">=</span> <span class="n">model_stability</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="34-模型评估方式混淆矩阵">3.4 模型评估方式——混淆矩阵</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">testY</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<h4 id="35-分类结果展示准确性召回率f1-score">3.5 分类结果展示（准确性，召回率，f1-score）</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">testY</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
</code></pre></div></div>

<h4 id="36-模型的保存和加载">3.6 模型的保存和加载</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>
<span class="c1"># 保存模型
</span><span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s">'model/model.model'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">))</span>
<span class="c1"># 导入模型
</span><span class="n">model</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">'model_save/model.model'</span><span class="p">,</span><span class="s">'wb'</span><span class="p">))</span>
</code></pre></div></div>

<h4 id="37-数据样本不均衡smoteenn">3.7 数据样本不均衡——SMOTEENN</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.combine</span> <span class="kn">import</span> <span class="n">SMOTEENN</span>
<span class="n">smote_enn</span> <span class="o">=</span> <span class="n">SMOTEENN</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_resampled</span><span class="p">,</span><span class="n">y_resampled</span> <span class="o">=</span> <span class="n">smote_enn</span><span class="p">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="38-自动超参调节">3.8 自动超参调节</h4>
<h5 id="381-自动调参gridsearchcv">3.8.1 自动调参——GridSearchCV</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">rcl</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">min_samples_split</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="s">'sqrt'</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># 现在不确定RandomForest其中一个参数n_estimators的个数
</span><span class="n">param_test1</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">71</span><span class="p">,</span><span class="mi">10</span><span class="p">)}</span>
<span class="n">gsearch1</span><span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span><span class="n">rcl</span><span class="p">,</span><span class="n">param_grid</span><span class="o">=</span>                                              <span class="n">param_test1</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">'roc_auc'</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gsearch1</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gsearch1</span><span class="p">.</span><span class="n">grid_scores_</span><span class="p">,</span> <span class="n">gsearch1</span><span class="p">.</span><span class="n">best_params_</span><span class="p">,</span> 	           <span class="n">gsearch1</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="382-自动调参神器hyperopt">3.8.2 自动调参神器——Hyperopt</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">hyperopt</span> <span class="kn">import</span> <span class="n">fmin</span><span class="p">,</span> <span class="n">tpe</span><span class="p">,</span> <span class="n">hp</span><span class="p">,</span> <span class="n">rand</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="c1"># SVM的三个超参数：C为惩罚因子，kernel为核函数类型，gamma为核函数的额外参数（对于不同类型的核函数有不同的含义）
# 有别于传统的网格搜索（GridSearch），这里只需要给出最优参数的概率分布即可，而不需要按照步长把具体的值给一个个枚举出来
</span><span class="n">parameter_space_svc</span> <span class="o">=</span><span class="p">{</span>
    <span class="c1"># loguniform表示该参数取对数后符合均匀分布
</span>    <span class="s">'C'</span><span class="p">:</span><span class="n">hp</span><span class="p">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">"C"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span>
    <span class="s">'kernel'</span><span class="p">:</span><span class="n">hp</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="s">'kernel'</span><span class="p">,[</span><span class="s">'rbf'</span><span class="p">,</span><span class="s">'poly'</span><span class="p">]),</span>
    <span class="s">'gamma'</span><span class="p">:</span> <span class="n">hp</span><span class="p">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">"gamma"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)),</span>
<span class="p">}</span>

<span class="c1"># 鸢尾花卉数据集，是一类多重变量分析的数据集
# 通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">load_digits</span><span class="p">()</span>

<span class="c1">#--------------------划分训练集和测试集--------------------
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1300</span><span class="p">]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1300</span><span class="p">]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1300</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test_target</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span><span class="p">[</span><span class="mi">1300</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1">#-----------------------------------------------------------
</span>
<span class="c1"># 计数器，每一次参数组合的枚举都会使它加1
</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">"C"</span><span class="p">]</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">"kernel"</span><span class="p">]</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">"gamma"</span><span class="p">]</span>

    <span class="c1"># **可以把dict转换为关键字参数，可以大大简化复杂的函数调用
</span>    <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">c</span><span class="p">,</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">,</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">)</span>

    <span class="c1"># 训练模型
</span>    <span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="n">train_target</span><span class="p">)</span>

    <span class="c1"># 预测测试集
</span>    <span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

    <span class="k">global</span> <span class="n">count</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_target</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"第%s次，测试集正确率为："</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">count</span><span class="p">),</span><span class="n">score</span><span class="p">)</span>

    <span class="c1"># 由于hyperopt仅提供fmin接口，因此如果要求最大值，则需要取相反数
</span>    <span class="k">return</span> <span class="o">-</span><span class="n">score</span>

<span class="c1"># algo指定搜索算法，目前支持以下算法：
# ①随机搜索(hyperopt.rand.suggest)
# ②模拟退火(hyperopt.anneal.suggest)
# ③TPE算法（hyperopt.tpe.suggest，算法全称为Tree-structured Parzen Estimator Approach）
# max_evals指定枚举次数上限，即使第max_evals次枚举仍未能确定全局最优解，也要结束搜索，返回目前搜索到的最优解
</span><span class="n">best</span> <span class="o">=</span> <span class="n">fmin</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">parameter_space_svc</span><span class="p">,</span> <span class="n">algo</span><span class="o">=</span><span class="n">tpe</span><span class="p">.</span><span class="n">suggest</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># best["kernel"]返回的是数组下标，因此需要把它还原回来
</span><span class="n">kernel_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'rbf'</span><span class="p">,</span><span class="s">'poly'</span><span class="p">]</span>
<span class="n">best</span><span class="p">[</span><span class="s">"kernel"</span><span class="p">]</span> <span class="o">=</span> <span class="n">kernel_list</span><span class="p">[</span><span class="n">best</span><span class="p">[</span><span class="s">"kernel"</span><span class="p">]]</span>

<span class="k">print</span><span class="p">(</span><span class="s">"最佳参数为："</span><span class="p">,</span><span class="n">best</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">best</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="39-to_categorical">3.9 to_categorical</h4>
<p>功能：将label转为one_hot形式，源于keras.utils包</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="n">y_onehot</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">num_classes</span><span class="p">(</span><span class="n">总类别数</span><span class="p">))</span>
</code></pre></div></div>

<h4 id="310-绘制roc曲线">3.10 绘制ROC曲线</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
<span class="k">def</span> <span class="nf">draw_ROC_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">savepath</span><span class="p">):</span>
    <span class="s">'''画ROC曲线'''</span>
    <span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'ROC'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">false_positive_rate</span><span class="p">,</span> <span class="n">true_positive_rate</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'AUC = %0.2f'</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'r--'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'TPR'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'FPR'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">savepath</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="四分类模型">四.分类模型</h3>
<h4 id="41-随机森林">4.1 随机森林</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">rf_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">700</span>
<span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">rf_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span><span class="n">trainY</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
<span class="c1"># 特征重要性
</span><span class="n">feature_importance</span> <span class="o">=</span> <span class="n">rf_clf</span><span class="p">.</span><span class="n">feature_importances_</span>
</code></pre></div></div>

<h4 id="42xgboost">4.2.Xgboost</h4>
<p>优势：表现快，训练时可以用所有的 CPU 内核来并行化建树；用分布式计算来训练非常大的模型；对于非常大的数据集还可以进行 Out-of-Core Computing)。参数：learning_rate ＝ 0.1 或更小，越小就需要多加入弱学习器；tree_depth ＝ 2～8；subsample ＝ 训练集的 30%～80%。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># 可以在每加入一颗树后打印出 logloss
</span><span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)]</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s">"logloss"</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="n">eval_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># 输出特征重要性
</span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">plot_importance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="n">plot_importance</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="43-svm">4.3 SVM</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s">'auto'</span><span class="p">,</span><span class="n">C</span><span class="p">,</span><span class="n">kernel</span> <span class="o">=</span> <span class="s">"RBF"</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testX</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="五聚类模型">五.聚类模型</h3>
<h4 id="51轮廓系数">5.1.轮廓系数</h4>
<p>评估聚类效果好坏——轮廓系数（Silhouette Coefficient）结合了聚类的凝聚度（Cohesion）和分离度（Separation），用于评估聚类的效果。该值处于-1~1之间，值越大，表示聚类效果越好。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#聚类评估：轮廓系数
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="c1"># Kmeans的聚类结果来进行测试
</span><span class="n">labels</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">labels_</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</code></pre></div></div>


      <div class="page-footer">
        <div class="page-share">
          <a href="https://twitter.com/intent/tweet?text=机器学习常用函数&url=http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a>
          <a href="https://facebook.com/sharer.php?u=http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a>
          <a href="https://plus.google.com/share?url=http://localhost:4000/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a>
        </div>
        <div class="page-tag">
          
            <a href="/tags#Pandas" class="tag">&#35; Pandas</a>
          
            <a href="/tags#Sklearn" class="tag">&#35; Sklearn</a>
          
        </div>
      </div>
      <section class="comment-area">
  <div class="comment-wrapper">
    
    <div id="disqus_thread" class="article-comments"></div>
    <script>
      (function() {
          var d = document, s = d.createElement('script');
          s.src = '//mr-brown.disqus.com/embed.js';
          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
  </div>
</section> <!-- End Comment Area -->

    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>
  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script> <!-- End Analytics -->

</body>
</html>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>