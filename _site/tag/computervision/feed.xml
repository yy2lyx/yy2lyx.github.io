<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="http://localhost:4000/tag/computervision/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2021-04-12T15:45:16+08:00</updated>
  <id>http://localhost:4000/tag/computervision/feed.xml</id>

  
  
  

  
    <title type="html">李小肥的YY | </title>
  

  
    <subtitle>欢迎各位看官光临本小站，希望共同学习进步哈！</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">windows下安装python-pcl</title>
      <link href="http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85PCL" rel="alternate" type="text/html" title="windows下安装python-pcl" />
      <published>2021-04-10T18:21:00+08:00</published>
      <updated>2021-04-10T18:21:00+08:00</updated>
      <id>http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85PCL</id>
      <content type="html" xml:base="http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85PCL">&lt;h3 id=&quot;一-准备工作&quot;&gt;一. 准备工作&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;python 版本：3.7.9&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;cython&lt;/li&gt;
      &lt;li&gt;numpy&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;python-pcl:1.9.1&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/strawlab/python-pcl&quot;&gt;python-pcl源码&lt;/a&gt;：后面需要进行编译&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/PointCloudLibrary/pcl/releases/&quot;&gt;PCL1.9.1的All-In-One Installer&lt;/a&gt; ：目前安装仅支持1.6到1.9的版本&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;visual studio 2019&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;a href=&quot;http://www.tarnyko.net/dl/gtk.htm&quot;&gt;Windows Gtk&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二-安装&quot;&gt;二. 安装&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将下载好的ALL-In-One Installer进行安装，这里会要求你添加到环境变量（必须添加啊），并且会安装OpenNI这个工具。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;解压下载好的windows Gtk，将&lt;code class=&quot;highlighter-rouge&quot;&gt;bin&lt;/code&gt;目录下所有文件复制到python-pcl源码目录下的&lt;code class=&quot;highlighter-rouge&quot;&gt;pkg-config&lt;/code&gt;目录下。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在&lt;code class=&quot;highlighter-rouge&quot;&gt;pkg-config&lt;/code&gt;目录下，运行脚本&lt;code class=&quot;highlighter-rouge&quot;&gt;InstallWindowsGTKPlus.bat&lt;/code&gt;，该脚本会下载必须的内容，下载完成后会多出这些文件夹，如下图所示&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/12/CtZmlOTNWhnakYU.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装python的pcl包：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cd 你安装python-pcl源码目录&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python setup.py build_ext -i&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python setup.py install&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三-安装遇到的坑&quot;&gt;三. 安装遇到的坑&lt;/h3&gt;

&lt;h4 id=&quot;31-坑一cannot-find-pcl&quot;&gt;3.1 坑一：cannot find PCL&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;问题：当你运行&lt;code class=&quot;highlighter-rouge&quot;&gt;python setup.py build_ext -i&lt;/code&gt;的时候报出：&lt;code class=&quot;highlighter-rouge&quot;&gt;setup.py: error: cannot find PCL, tried 		pkg-config pcl_common-1.7 		pkg-config pcl_common-1.6 		pkg-config pcl_common&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;解决方案：这里就是上面说的，别下除了1.6到1.9版本的pcl的All-In-One Installer啊。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;32-坑二dll-load-failed&quot;&gt;3.2 坑二：DLL load failed&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;问题：全部安装完成之后，一切没有问题了，当你打开python，运行&lt;code class=&quot;highlighter-rouge&quot;&gt;import pcl&lt;/code&gt;的时候报出：&lt;code class=&quot;highlighter-rouge&quot;&gt;DLL load failed&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;解决方案：重启电脑！&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;四-python版本的使用&quot;&gt;四. python版本的使用&lt;/h3&gt;

&lt;h4 id=&quot;41--点云数据的展示python&quot;&gt;4.1  点云数据的展示（python）&lt;/h4&gt;

&lt;p&gt;构建点云–Point_XYZRGBA格式(需要点云数据是N*4，分别表示x,y,z,RGB ,其中RGB 用一个整数表示颜色)，下面是python版本的点云数据展示&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pcl&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pcl.pcl_visualization&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;viewer&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;#可视化库&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# cloud = pcl.load(&quot;cloud.pcd&quot;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cloud_np&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cloud.npy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cloud&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pcl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PointCloud_PointXYZRGBA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cloud_np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;visual&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pcl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pcl_visualization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CloudViewing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;visual&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ShowColorACloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cloud&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;visual&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WasStopped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;42-命令行展示&quot;&gt;4.2 命令行展示&lt;/h4&gt;

&lt;p&gt;由于上面已经下载了PCL1.9.1了，可以直接在命令行中进行展示：&lt;code class=&quot;highlighter-rouge&quot;&gt;pcl_viewer_release H cloud.PCD&lt;/code&gt;，下面的是来自Middlebury 2014数据集中经过立体匹配后的3D点云图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/12/cPJwuA8LgHUmFDf.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="ComputerVision" />
      
        <category term="PCL" />
      

      
        <summary type="html">介绍如何在win10下安装python版本的PCL点云库</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">目标检测(one stage)-SSD</title>
      <link href="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_2" rel="alternate" type="text/html" title="目标检测(one stage)-SSD" />
      <published>2021-04-04T04:21:00+08:00</published>
      <updated>2021-04-04T04:21:00+08:00</updated>
      <id>http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_2</id>
      <content type="html" xml:base="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_2">&lt;h3 id=&quot;一-yolo和ssd的对比&quot;&gt;一. YOLO和SSD的对比&lt;/h3&gt;

&lt;p&gt;yolo和ssd两个模型结构如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/uC7PiazmWIbq2kJ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;两个模型之间最主要的差别：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在特征抽取层其实相差不大：YOLO用的是器自己的conv架构；SSD用的是VGG-16&lt;/li&gt;
  &lt;li&gt;主要差别在结果预测上：YOLO用的是全连接层后得到7*7的grid，利用每个grid的boundingbox来做目标检测；SSD利用不同大小的feature map来做目标检测。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二-模型结构&quot;&gt;二. 模型结构&lt;/h3&gt;

&lt;h4 id=&quot;21-特征抽取层&quot;&gt;2.1 特征抽取层&lt;/h4&gt;

&lt;p&gt;那么如何从VGG-16的结构变成SSD的结构呢?下图是一个VGG-16的示意图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/fKEV8UWLTvPGmQ3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;将VGG-16的最后一层pooling层变成3*3 的卷积层，再接一个atrous conv（空洞卷积）拿到不同大小的feature map。如下所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/qdFiaXwTlJUmS9p.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;22-空洞卷积&quot;&gt;2.2 空洞卷积&lt;/h4&gt;

&lt;p&gt;这里运用atrous conv layer而不是普通的conv layer的目的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在相同的感受野的同时，能获得更快的运算速度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如下图所示，是5 * 5 的卷积的kernel和3 * 3的atrous conv的kernel的感受野。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/HPzOvInK6fhstr2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，如果是3 * 3的conv层接5 * 5的conv层，那么feature map中单一点的感受野其实是7个像素点；而如果是3 * 3的conv层接3 * 3的atrous conv层，能达到相同的感受野，且计算速度更快。&lt;/p&gt;

&lt;h4 id=&quot;22-推理层&quot;&gt;2.2 推理层&lt;/h4&gt;

&lt;p&gt;下图是SSD的推理层的示意图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/83wrMCQ5YJajBGz.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，图片经过vgg16之后，首先会得到较浅的feature map,随后经过几层卷积之后，得到较为深层的feature map（所以在上图中仅有较深层的能检测到车这种大物体），同时每层的feature map都会经过一个检测器和分类器得到检测结果，最后经过NMS得到最终的检测结果。&lt;/p&gt;

&lt;p&gt;那么整个SSD的anchor box的数量是：
&lt;script type=&quot;math/tex&quot;&gt;38*38*3+19*19*6+10*10*6+5*5*6+3*3*6+1*1*6 = 7308&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;三-模型训练&quot;&gt;三. 模型训练&lt;/h3&gt;

&lt;h4 id=&quot;31训练loss&quot;&gt;3.1训练loss&lt;/h4&gt;

&lt;p&gt;SSD和YOLO的loss中的检测类别值有所不同：假定检测目标一共A个类别，那么YOLO的预测类别数位A个，而SSD的预测类别则是A+1个（包含了背景类）。如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/nqH2h5B6CtupZSs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;32-难负例挖掘&quot;&gt;3.2 难负例挖掘&lt;/h4&gt;

&lt;p&gt;对于正负样本不均衡的情况，SSD采用了hard negative mining(难负例挖掘)技巧来解决。hard negative是指在图片中容易将负样本（背景）看成是正样本（前景）的样本。而mining的操作就是将这类样本放入模型进行学习，从而减少模型的false positive。&lt;/p&gt;

&lt;p&gt;那么SSD是如何引用hard negative mining技巧呢？如下图，其中蓝色的box的我们希望它的confidence较低，而绿色的confidence较高。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于一张图而言，选出其中anchor box中negative置信度较高的box。&lt;/li&gt;
  &lt;li&gt;正负比例的anchor box = 1：3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/Z8uVQvXyMs2SKhR.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;32-数据增强&quot;&gt;3.2 数据增强&lt;/h4&gt;

&lt;p&gt;SSD模型在论文中也使用了很多不同的data augmentation(数据增强)的操作。&lt;/p&gt;

&lt;p&gt;方式一：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;针对原始输入图片和ground truth进行IOU的操作&lt;/li&gt;
  &lt;li&gt;对其中iou = 0.1，0.3，0.5，0.7和0.9来进行采样。&lt;/li&gt;
  &lt;li&gt;对采样后的图片进行resize成相同大小的图片，然后进行水平翻转的操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/h4K3V1XzYRLFQwg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;方式二（Random Expansion-得到的小目标训练样本）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对原始图像做不同比例的缩小。&lt;/li&gt;
  &lt;li&gt;然后放在相同大小图片中不同的地方。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/E48HkqysBPFw9JV.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;四-结果比较&quot;&gt;四. 结果比较&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/06/uKA6pBnV71YRFah.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，SSD相较于YOLO在准确性上有很大的提升，同时预测速度上也能达到很高的fps。&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="ComputerVision" />
      
        <category term="DeepLearning" />
      
        <category term="SSD" />
      

      
        <summary type="html">目标检测（one stage）——SSD</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">目标检测(one stage)-YOLOv1</title>
      <link href="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_1" rel="alternate" type="text/html" title="目标检测(one stage)-YOLOv1" />
      <published>2021-03-11T04:21:00+08:00</published>
      <updated>2021-03-11T04:21:00+08:00</updated>
      <id>http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_1</id>
      <content type="html" xml:base="http://localhost:4000/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B_1">&lt;h3 id=&quot;一-目标检测算法的分类及历史&quot;&gt;一. 目标检测算法的分类及历史&lt;/h3&gt;

&lt;h4 id=&quot;11-目标检测算法的分类&quot;&gt;1.1 目标检测算法的分类&lt;/h4&gt;

&lt;p&gt;目标检测算法主要分为2大类：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;one-stage(one-shot object detectors) ：直接预测目标的bounding box及其类别。特点是一步到位，速度很快。比如：YOLO，SSD等系列模型。&lt;/li&gt;
  &lt;li&gt;two-stage：需要先使用启发式方法(selective search)或者CNN网络(RPN)产生Region Proposal，然后再在Region Proposal上做分类与回归。特点是：慢，但是准确率高。比如：RCNN系列模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;由于在工业应用中，往往对模型预测速度有要求，而two-stage目标检测模型由于先天的不足，因此本文仅考虑one-stage目标检测模型。&lt;/p&gt;

&lt;h4 id=&quot;12-目标检测发展流程&quot;&gt;1.2 目标检测发展流程&lt;/h4&gt;

&lt;p&gt;目标检测（one-stage）的总体发展流程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2015.06 — YOLOv1：第一个one-stage目标检测器。&lt;/li&gt;
  &lt;li&gt;2015.12 — SSD：结合anchor box和多尺度特征的one-stage目标检测器。&lt;/li&gt;
  &lt;li&gt;2016.12 — YOLOv2：YOLO的第二版。&lt;/li&gt;
  &lt;li&gt;2016.12 — FPN：特征金字塔（结合不同尺寸的特征图像）&lt;/li&gt;
  &lt;li&gt;2017.01 — DSSD：SSD结合FPN。&lt;/li&gt;
  &lt;li&gt;2017.08 — RetinaNet：Focal Loss解决正负样本不均衡&lt;/li&gt;
  &lt;li&gt;2018.04 — YOLOv3：YOLO的第三版。&lt;/li&gt;
  &lt;li&gt;2018.07 — CBAM：Attention机制的目标检测。&lt;/li&gt;
  &lt;li&gt;2019.11 — EfficientDet：Google提出的目标检测器。&lt;/li&gt;
  &lt;li&gt;2020.04 — YOLOv4：YOLO的第四版。&lt;/li&gt;
  &lt;li&gt;2020.06 — YOLOv5：YOLO第五版。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二-yolo&quot;&gt;二. YOLO&lt;/h3&gt;

&lt;p&gt;当我最初学习图像分类的时候，就一直疑惑：如果我利用卷积层抽取目标特征后直接把分类任务做成回归任务（包含目标的位置和类别信息）可以作为目标检测器么？答案来了——YOLO（You Look Only Once）。&lt;/p&gt;

&lt;h4 id=&quot;21-模型结构&quot;&gt;2.1 模型结构&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/bAs2nLNVF5uWijZ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;YOLO模型的结构如上所示：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;输入为一个448*448的一个图片输入。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;一共是经过24层的卷积层抽取特征，使用relu作为每一层的激活函数。&lt;/li&gt;
  &lt;li&gt;最后通过全连接层，且output形式为[7,7,30]的输出。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;模型输出的理解：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将448 * 448的图像分为7 * 7的grid（网格），每个grid都会进行判断：是否为前景，且会构建2个boundingbox来框出物体。因此，一共是有7 * 7 * 2个框。而每个grid都会输出x,y,w,h,c；这里的confidence的计算就是前景目标的概率 * iou的值。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/p5KV6fZGaQCqUMT.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;除了boundingbox的计算外，当然还需要输出目标是哪个类别，即输出检测到的目标是某个类别的概率。这样就可以计算每个grid属于某个类别下的iou情况了。&lt;/li&gt;
  &lt;li&gt;最后利用NMS（非极大值抑制：顾名思义就是不是最大的置信度就不要了）找到每个目标的最合适的框。具体NMS的算法步骤如下：
    &lt;ul&gt;
      &lt;li&gt;（1）首先拿到的是YOLO模型输出的结果，即7 * 7 * 2个框，每个框都是由5个元素（x,y,w,h,c）。这里需要知道一张图片中有多少个目标且目标confidence最高的结果。&lt;/li&gt;
      &lt;li&gt;（2）通过计算两两框之间的IOU（交并比），用来划分一张图片中有多少个目标（如果IOU&amp;gt;0说明属于同一目标下的框）。&lt;/li&gt;
      &lt;li&gt;（3）对同一目标下的所有框的confidence进行排序，找到最大的的confidence对应的框。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22-模型训练&quot;&gt;2.2 模型训练&lt;/h4&gt;

&lt;p&gt;这里主要讲述模型训练过程中loss的定义过程。&lt;/p&gt;

&lt;h5 id=&quot;221-location-loss&quot;&gt;2.2.1 Location Loss&lt;/h5&gt;

&lt;p&gt;定义如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/ZLlQj29WeVTdzRI.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/oeTrzxY4auHEG8c.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上所示，假定是将图片划分为3 * 3个grid，每个grid有且仅有一个预测框，由于只计算和前景目标匹配的框，因此只会计算grid5和grid7的location loss。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;grid5的loss：&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/G7TUCNdS5lWDKrw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;grid7的loss：&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/nBHViDx8kpRjGZ9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但是这里看大大猫和小猫的loss竟然是一样的，大猫的loss应该明显要小一些，而小猫的loss明显要大一些。因此这种loss的计算还需要提升。这里就将w,h的分别先进行&lt;strong&gt;开根号&lt;/strong&gt;处理。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;grid5的loss：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/ZA2t1zlJKIu9XMD.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;grid7的loss：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/hlRF8OMHrt6wXnk.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;222-object-loss&quot;&gt;2.2.2 Object Loss&lt;/h5&gt;

&lt;p&gt;定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/N9KPlvfTF1OCuWE.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么上图的每个grid的confidence的值如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/jlszbUxcCQTLqIK.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;object loss的值为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/HvNnV8h6eZdoWE7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是这个是只划分了3 * 3个grid的，那么如果是原论文中的7 * 7的情况下呢，此时的object loss的值为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/WqYcKHxbveoRhQL.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看到，0.96这个检测的背景的loss就过大了，那么在反向传播的过程中，梯度的变化很大程度就着重在背景的部分，以至于学习前景的能力较差。&lt;/p&gt;

&lt;p&gt;因此，重新定义object loss（其实就是在背景loss引入一个系数，比如0.5）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/ctsYBoIguWzlab7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;223-classification-loss&quot;&gt;2.2.3 classification loss&lt;/h5&gt;

&lt;p&gt;定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/fI6jQpviDU5Kswo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;24-yolo存在问题&quot;&gt;2.4 YOLO存在问题&lt;/h4&gt;

&lt;h5 id=&quot;241-同一个grid却是多个目标的中心点&quot;&gt;2.4.1 同一个grid却是多个目标的中心点&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/iLWdGr6kxPAUplD.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，人和车的中心点基本都落在中心的grid中，对于yolo而言，就无法分辨到底是人还是车？一个grid下只能预测1个目标。&lt;/p&gt;

&lt;h5 id=&quot;242-同一个grid中存在多个小目标&quot;&gt;2.4.2 同一个grid中存在多个小目标&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/03/16/UmrSYCLP7MdTXab.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，同一个grid下有多个鸟（小目标），而对于yolo而言，一个grid下只能预测1个目标。&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="yolo" />
      
        <category term="ComputerVision" />
      
        <category term="DeepLearning" />
      

      
        <summary type="html">目标检测（one stage）的开始——YOLOv1</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">pytorch使用YOLOv5训练数据</title>
      <link href="http://localhost:4000/pytorch%E4%BD%BF%E7%94%A8YOLOv5%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE" rel="alternate" type="text/html" title="pytorch使用YOLOv5训练数据" />
      <published>2020-10-27T03:21:00+08:00</published>
      <updated>2020-10-27T03:21:00+08:00</updated>
      <id>http://localhost:4000/pytorch%E4%BD%BF%E7%94%A8YOLOv5%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE</id>
      <content type="html" xml:base="http://localhost:4000/pytorch%E4%BD%BF%E7%94%A8YOLOv5%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">&lt;h3 id=&quot;一-需要下载的资源&quot;&gt;一. 需要下载的资源&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Fork 下官方的开源项目：https://github.com/ultralytics/yolov5&lt;/li&gt;
  &lt;li&gt;git clone 下Fork之后的项目到自己本地仓库中。&lt;/li&gt;
  &lt;li&gt;采用的训练集（简单的，仅有一个类）：源自&lt;a href=&quot;https://www.kaggle.com/c/global-wheat-detection/data&quot;&gt;Kaggle的小麦数据集&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;如果有gpu的话，最好安装cuda进行训练加速，这里可以参考本人的另一篇文章：&lt;a href=&quot;https://yy2lyx.github.io/Windows10%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%90%AD%E5%BB%BACUDA10.1%E5%92%8Cpytorch1.6/&quot;&gt;Windows10环境下搭建CUDA10.1和pytorch1.6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二--构建属于自己的目标检测模型&quot;&gt;二 . 构建属于自己的目标检测模型&lt;/h3&gt;

&lt;h4 id=&quot;21-在官网的开源yolo5项目的基础上进行构建&quot;&gt;2.1 在官网的开源yolo5项目的基础上进行构建&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;git 克隆到本地仓库：&lt;code class=&quot;highlighter-rouge&quot;&gt;git clone https://github.com/xx/yolov5.git&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;进入项目中，并安装需要的第三方依赖：&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;新建一个原始数据的目录：：&lt;code class=&quot;highlighter-rouge&quot;&gt;mkdir ori_data&lt;/code&gt;，将下载好的小麦数据集解压后放到项目。&lt;/li&gt;
  &lt;li&gt;创建输出一个文件输出目录：&lt;code class=&quot;highlighter-rouge&quot;&gt;mkdir wheat_data&lt;/code&gt;，并在此目录下新建以下目录，如下图所示
    &lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;├─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;images&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;│&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;├─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;train&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;│&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;└─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;└─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;labels&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;├─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;train&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;└─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;构建数据集，新建一个&lt;code class=&quot;highlighter-rouge&quot;&gt;munge_data.py&lt;/code&gt;文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ast&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;shutil&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ori_data'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wheat_data'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterrows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'image_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bounding_boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bounding_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# 这里需要将图像数据归一化处理（yolo需要的输入为归一化后的数据,且为浮点数）&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_center&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_center&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# 保存bbox的图片信息&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savetxt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'labels/{data_type}/{image_name}.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;fmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# 将目标图片文件保存到指定文件中&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shutil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copyfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train/{image_name}.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'images/{data_type}/{image_name}.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 将string of list 转成list数据&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;literal_eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 利用groupby 将同一个image_id的数据进行聚合，方式为list进行，并且用reset_index直接转变成dataframe&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'image_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 划分数据集&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 重设 index （这里数据被打乱，index改变混乱）&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;process_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;process_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'val'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;运行构建数据的py文件：&lt;code class=&quot;highlighter-rouge&quot;&gt;python munge_data.py&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里可以看到在输出结果目录中，放入了需要的整理后的数据集&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新建一个&lt;code class=&quot;highlighter-rouge&quot;&gt;wheat.yaml&lt;/code&gt;yaml文件，指定模型训练时候的输入及其类别（注意这里冒号后面要加空格，yamal格式问题）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wheat_data/images/train // 指定训练目录&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wheat_data/images/val // 指定验证目录&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;nc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1 // 指定类别&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;wheat&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;// 指定类别名字&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;进行模型训练：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 train.py &lt;span class=&quot;nt&quot;&gt;--img&lt;/span&gt; 1024 &lt;span class=&quot;nt&quot;&gt;--batch&lt;/span&gt; 8 &lt;span class=&quot;nt&quot;&gt;--epoch&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--data&lt;/span&gt; wheat.yaml &lt;span class=&quot;nt&quot;&gt;--cfg&lt;/span&gt; .&lt;span class=&quot;se&quot;&gt;\m&lt;/span&gt;odels&lt;span class=&quot;se&quot;&gt;\y&lt;/span&gt;olov5s.yaml &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; wm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里可能会报错（Dataloader中设置了多进程导致的），报错信息如下所示：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;File &lt;span class=&quot;s2&quot;&gt;&quot;C:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\s&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;oft&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\p&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ython3.7.9&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\l&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ib&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\m&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ultiprocessing&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;eduction.py&quot;&lt;/span&gt;, line 60, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;dump     
ForkingPickler&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;file, protocol&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.dump&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;obj&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; BrokenPipeError: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Errno 32] Broken pipe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里可以参考文章：https://github.com/pytorch/pytorch/issues/2341。解决方案：将&lt;code class=&quot;highlighter-rouge&quot;&gt;utils\datasets.py&lt;/code&gt;文件中&lt;code class=&quot;highlighter-rouge&quot;&gt;num_workers&lt;/code&gt;改成0即可（代码第68行）。训练完成后如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gk47ziddqvj30jg01vt8i.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以查看本地tensorboard训练过程：&lt;code class=&quot;highlighter-rouge&quot;&gt;tensorboard --logdir=runs&lt;/code&gt;，如果这里出现问题，可以换成一下命令：&lt;code class=&quot;highlighter-rouge&quot;&gt;python -m tensorboard.main --logdir logs&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gk4804vrrkj310d0gajt5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这里还可以使用coco数据集的&lt;a href=&quot;https://drive.google.com/drive/folders/1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J&quot;&gt;预训练模型&lt;/a&gt;进行训练，可能效果会更好&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 train.py &lt;span class=&quot;nt&quot;&gt;--img&lt;/span&gt; 1024 &lt;span class=&quot;nt&quot;&gt;--batch&lt;/span&gt; 8 &lt;span class=&quot;nt&quot;&gt;--epoch&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--data&lt;/span&gt; wheat.yaml &lt;span class=&quot;nt&quot;&gt;--cfg&lt;/span&gt; .&lt;span class=&quot;se&quot;&gt;\m&lt;/span&gt;odels&lt;span class=&quot;se&quot;&gt;\y&lt;/span&gt;olov5s.yaml &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; wm &lt;span class=&quot;nt&quot;&gt;--weights&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将训练好的模型放到当前文件夹下：&lt;code class=&quot;highlighter-rouge&quot;&gt;cp runs/exp0_wm/weights/best.pt . &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;选择测试图片的文件夹进行生成测试：&lt;code class=&quot;highlighter-rouge&quot;&gt;python detect.py --source ./test_data --weights best.pt &lt;/code&gt;，这里可以看到新生成一个文件夹&lt;code class=&quot;highlighter-rouge&quot;&gt;inference/output&lt;/code&gt;中就是测试后标记bbox后的图片。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="pytorch" />
      
        <category term="ComputerVision" />
      
        <category term="DeepLearning" />
      

      
        <summary type="html">介绍如何利用官方开源的Yolov5训练一个属于自己的模型</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Visual Studio 2019 下搭建opencv3.4.11的C++环境</title>
      <link href="http://localhost:4000/Visual-Studio-2019-%E4%B8%8B%E6%90%AD%E5%BB%BAopencv3.4.11%E7%9A%84C++%E7%8E%AF%E5%A2%83" rel="alternate" type="text/html" title="Visual Studio 2019 下搭建opencv3.4.11的C++环境" />
      <published>2020-10-16T03:21:00+08:00</published>
      <updated>2020-10-16T03:21:00+08:00</updated>
      <id>http://localhost:4000/Visual%20Studio%202019%20%E4%B8%8B%E6%90%AD%E5%BB%BAopencv3.4.11%E7%9A%84C++%E7%8E%AF%E5%A2%83</id>
      <content type="html" xml:base="http://localhost:4000/Visual-Studio-2019-%E4%B8%8B%E6%90%AD%E5%BB%BAopencv3.4.11%E7%9A%84C++%E7%8E%AF%E5%A2%83">&lt;h3 id=&quot;一-下载需要的软件&quot;&gt;一. 下载需要的软件&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://visualstudio.microsoft.com/zh-hans/downloads/&quot;&gt;visual studio 2019 社区版&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://opencv.org/releases/&quot;&gt;opencv3.4.11&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二-基于c的环境搭建&quot;&gt;二. 基于C++的环境搭建&lt;/h3&gt;
&lt;h4 id=&quot;21-创建系统环境变量&quot;&gt;2.1 创建系统环境变量&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;解压opencv，到&lt;code class=&quot;highlighter-rouge&quot;&gt;D:\software&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;配置系统变量：Path下添加Opencv的路径&lt;code class=&quot;highlighter-rouge&quot;&gt;D:\software\opencv\opencv\build\x64\vc15\bin&lt;/code&gt;（这里选择vc15更适合vs2019，如果是vs2015就选择vc14）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22-在visual-studio2019中配置opencv&quot;&gt;2.2 在Visual Studio2019中配置Opencv&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;选择视图-属性管理器- 选择Debugx64-添加新项目属性表-这里选择保存的名称和位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrjssvz0fj30qc0hydg5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;选择VC++目录-包含目录中添加以下
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;D:\software\opencv\opencv\build\include
D:\software\opencv\opencv\build\include\opencv
D:\software\opencv\opencv\build\include\opencv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;选择VC++目录-库目录中添加&lt;code class=&quot;highlighter-rouge&quot;&gt;D:\software\opencv\opencv\build\x64\vc15\lib&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;选择链接器-输入-附加依赖项中添加&lt;code class=&quot;highlighter-rouge&quot;&gt;opencv_world3411d.lib&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;保存即可，注意这里构建的新建项目属性表可以保存下来，直接其他的项目直接导入用即可（视图-属性管理器- 选择Debugx64-添加现有属性表）&lt;/li&gt;
  &lt;li&gt;回到解决方案资源管理器-项目-属性-配置管理器-活动解决方案平台-选择x64-Debug&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gjrjt4rjq6j30j50dfmx9.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;三-构建代码测试&quot;&gt;三. 构建代码测试&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;构建cpp源码：解决方案-源文件-添加-新建项-cpp文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用以下代码进行测试&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include&amp;lt;iostream&amp;gt;
#include&amp;lt;opencv2/core/core.hpp&amp;gt;
#include&amp;lt;opencv2/highgui/highgui.hpp&amp;gt;
#include&amp;lt;opencv2/opencv.hpp&amp;gt;
#include&amp;lt;math.h&amp;gt;
&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;//Mat img = imread(&quot;D:\\vs_project\\opencvtest\\1.jpg&quot;);
&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Mat&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;D:/vs_project/opencvtest/1.jpg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Could not load img...&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;namedWindow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ori_img&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WINDOW_AUTOSIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ori_img&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// 图像转成灰度图像
&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;Mat&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gray_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cvtColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gray_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CV_RGB2GRAY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;namedWindow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gray_img&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WINDOW_AUTOSIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;gray_img&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gray_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;waitKey&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;


	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="环境搭建" />
      
        <category term="ComputerVision" />
      

      
        <summary type="html">在Windows下利用Visual Studio2019 来搭建opencv3.4.11的C++环境</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Xcode搭建Opencv3环境</title>
      <link href="http://localhost:4000/Xcode%E6%90%AD%E5%BB%BAOpencv3%E7%8E%AF%E5%A2%83" rel="alternate" type="text/html" title="Xcode搭建Opencv3环境" />
      <published>2020-10-14T03:21:00+08:00</published>
      <updated>2020-10-14T03:21:00+08:00</updated>
      <id>http://localhost:4000/Xcode%E6%90%AD%E5%BB%BAOpencv3%E7%8E%AF%E5%A2%83</id>
      <content type="html" xml:base="http://localhost:4000/Xcode%E6%90%AD%E5%BB%BAOpencv3%E7%8E%AF%E5%A2%83">&lt;h4 id=&quot;1-下载opencv&quot;&gt;1. 下载opencv&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;使用简单粗暴的方式——brew进行安装：&lt;code class=&quot;highlighter-rouge&quot;&gt;brew install opencv@3&lt;/code&gt;，注意这里通过brew下载的opencv3的地址为：&lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/local/Cellar/opencv@3/3.4.9_1&lt;/code&gt;（后面配置include和lib有用）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里存在很大的问题：brew除了下载opencv以外还需要下载opencv的依赖包（很多），这里强力推荐换brew的镜像源（本人用的清华的，当然也可以用中科大的）。具体配置方式如下：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;第一步：替换brew.git：&lt;/p&gt;

        &lt;div class=&quot;language-powershell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;brew --repo&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
git remote &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;第二步：替换 homebrew-core.git：
      &lt;code class=&quot;highlighter-rouge&quot;&gt;powershell
  cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;
  git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git
 &lt;/code&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-在xcode上搭建opencv的环境&quot;&gt;2. 在Xcode上搭建opencv的环境&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;新建项目：macOS - Command Line Tool - 这里选择语言为C++&lt;/li&gt;
  &lt;li&gt;点击项目，选择Build Settings- 在搜索框中搜索search。&lt;/li&gt;
  &lt;li&gt;在头文件路径Header Search Paths中debug中添加一下&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/usr/local/Cellar/opencv@3/3.4.9_1/include
/usr/local/Cellar/opencv@3/3.4.9_1/include/opencv
/usr/local/Cellar/opencv@3/3.4.9_1/include/opencv2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gjo3k6yqj6j31qa0ssaow.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在Library Search Paths中添加&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/usr/local/Cellar/opencv@3/3.4.9_1/lib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;在项目中添加动态链接库文件：选择项目- 右键New Group - 新建一个名字（比如lib）- 右键lib - Add files to - 按下&lt;code class=&quot;highlighter-rouge&quot;&gt;/&lt;/code&gt;会直接提示到那个目录下找dylib，这里是&lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/local/Cellar/opencv@3/3.4.9_1/lib&lt;/code&gt;，把当前目录下的所有dylib都添加进去即可，如下图。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gjo3v21p6hj31q80f2tap.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;以上就是整个opencv3在Xcode的环境了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-测试案例&quot;&gt;3. 测试案例&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-C&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;opencv2/opencv.hpp&amp;gt;
#include &amp;lt;opencv2/highgui/highgui.hpp&amp;gt;


using namespace std;
using namespace cv;

int main(int argc, const char * argv[]) {
    // insert code here...
    cout &amp;lt;&amp;lt; &quot;This is my first try C++ in xcode!\n&quot;;
    
    Mat img = imread(&quot;/Users/xcode_project/C++_project/opencvTutorial/test.jpeg&quot;);
    if (img.empty()){
        cout &amp;lt;&amp;lt; &quot;Could not open image ...&quot;&amp;lt;&amp;lt; endl;
        return -1;
    }
    namedWindow(&quot;test&quot;,CV_WINDOW_AUTOSIZE);
    imshow(&quot;test&quot;, img);
    waitKey(0);
    
    
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="ComputerVision" />
      
        <category term="环境搭建" />
      

      
        <summary type="html">在Mac中利用Xcode神器搭建opencv3的C++环境</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">Windows下安装C++ IDE（clion）和opencv环境</title>
      <link href="http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85C++-IDE-clion-%E5%92%8Copencv%E7%8E%AF%E5%A2%83" rel="alternate" type="text/html" title="Windows下安装C++ IDE（clion）和opencv环境" />
      <published>2019-10-01T18:18:00+08:00</published>
      <updated>2019-10-01T18:18:00+08:00</updated>
      <id>http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85C++%20IDE(clion)%E5%92%8Copencv%E7%8E%AF%E5%A2%83</id>
      <content type="html" xml:base="http://localhost:4000/Windows%E4%B8%8B%E5%AE%89%E8%A3%85C++-IDE-clion-%E5%92%8Copencv%E7%8E%AF%E5%A2%83">&lt;h4 id=&quot;1-下载软件&quot;&gt;1. 下载软件&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.macw.com/mac/1893.html&quot;&gt;clion&lt;/a&gt;：C++的IDE&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cmake.org/download/&quot;&gt;cmake&lt;/a&gt; : 这里需要添加到环境变量中 &lt;code class=&quot;highlighter-rouge&quot;&gt;D:\Profile\mingw64\bin&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;[https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/8.1.0/threads-posix/seh/x86_64-8.1.0-release-posix-seh-rt_v6-rev0.7z/download](https://sourceforge.net/projects/mingw-w64/files/Toolchains targetting Win64/Personal Builds/mingw-builds/8.1.0/threads-posix/seh/x86_64-8.1.0-release-posix-seh-rt_v6-rev0.7z/download)&quot;&gt;MinGW&lt;/a&gt; ：添加到环境变量 &lt;code class=&quot;highlighter-rouge&quot;&gt;D:\Profile\mingw64\bin&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://opencv.org/releases/&quot;&gt;opencv3.4.10&lt;/a&gt;：开源的计算机视觉库&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-mingw和opencv&quot;&gt;2. MinGW和OpenCV&lt;/h4&gt;

&lt;p&gt;主要是如何用你的编译器来编译OpenCV。我们需要有include文件夹，这个在写代码时就用的到，还有lib和dll，这俩货我也不是很懂，dll的话没有是可以编译成功的，但运行是要失败的，所以我们是肯定要把dll加入到系统环境变量Path里的。lib是编译时就需要的，所以我们得把lib放在CLion的CMakeLists里面。&lt;/p&gt;

&lt;p&gt;下载完Windows的OpenCV，其实我们只有给Visual Studio用的dll和lib，可是我们想要g++来编译和运行，所以就得自己根据OpenCV的sources文件夹来自己编译OpenCV。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这里需要在cmake中加入&lt;code class=&quot;highlighter-rouge&quot;&gt;OPENCV_ALLOCATOR_STATS_COUNTER_TYPE=int64_t&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;add Entry&lt;/code&gt; ==&amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;string&lt;/code&gt;，这里参考&lt;a href=&quot;https://github.com/opencv/opencv/issues/17065&quot;&gt;报错信息1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;这里还需要再cmake中加入&lt;code class=&quot;highlighter-rouge&quot;&gt;OPENCV_ENABLE_ALLOCATOR_STATS=OFF&lt;/code&gt;，参考&lt;a href=&quot;https://answers.opencv.org/question/228737/gcc-error-long-no-such-file-or-directory/&quot;&gt;报错信息2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1gjehgzemrbj30fl0ep0ug.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;需要2次Configure和1次Genrate即可编译完成。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cd opencv\mingw-build&lt;/code&gt;目录下输入&lt;code class=&quot;highlighter-rouge&quot;&gt;mingw32-make&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;等待完成，&lt;code class=&quot;highlighter-rouge&quot;&gt;mingw32-make install&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;打开你的mingw-build文件夹，里面有个install目录就是你要的，可以复制一下这个文件夹，以后就不用重新编译了。我在C盘建立了OpenCV目录，并且把install文件夹下的文件复制进去了,&lt;code class=&quot;highlighter-rouge&quot;&gt;C:\OpenCV\x64\mingw\bin&lt;/code&gt;加入系统环境变量Path中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-写cmakelist&quot;&gt;3. 写CMakeList&lt;/h4&gt;

&lt;p&gt;其实就是加入lib目录和include目录&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cmake_minimum_required(VERSION 3.16)
project(opencv_test)

set(CMAKE_CXX_STANDARD 14)

add_executable(opencv_test main.cpp)

## 添加的OpenCVConfig.cmake的路径
set(OpenCV_DIR &quot;D:/Profile/opencv_builded&quot;)

## 搜索OpenCV目录
find_package(OpenCV REQUIRED)

## 添加OpenCV头文件目录
include_directories(&quot;D:/Profile/opencv_builded/include&quot;)

## 链接OpenCV库文件
target_link_libraries(opencv_test ${OpenCV_LIBS})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;4-编译成可执行文件&quot;&gt;4. 编译成可执行文件&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;main.cpp&lt;/code&gt;文件中写完后，&lt;code class=&quot;highlighter-rouge&quot;&gt;cd 项目目录&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;cmake .&lt;/code&gt;，即可看到项目中新加了文件夹&lt;code class=&quot;highlighter-rouge&quot;&gt;cmake-build-debug&lt;/code&gt;中里面存在&lt;code class=&quot;highlighter-rouge&quot;&gt;.exe&lt;/code&gt;可执行文件。&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="ComputerVision" />
      
        <category term="环境搭建" />
      

      
        <summary type="html">讲述如何在Windows环境中安装clion和配置opencv环境</summary>
      

      
      
    </entry>
  
</feed>
