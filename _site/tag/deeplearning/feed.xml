<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="http://localhost:4000/tag/deeplearning/feed.xml" rel="self" type="application/atom+xml" />
  <link href="http://localhost:4000/" rel="alternate" type="text/html" />
  <updated>2021-01-22T17:38:31+08:00</updated>
  <id>http://localhost:4000/tag/deeplearning/feed.xml</id>

  
  
  

  
    <title type="html">李小肥的YY | </title>
  

  
    <subtitle>欢迎各位看官光临本小站，希望共同学习进步哈！</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">windows下搭建libtorch和paddle的C++环境搭建</title>
      <link href="http://localhost:4000/windows-%E4%B8%8B%E6%90%AD%E5%BB%BAlibtorch%E5%92%8Cpaddle%E7%9A%84C++%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA" rel="alternate" type="text/html" title="windows下搭建libtorch和paddle的C++环境搭建" />
      <published>2020-11-27T04:21:00+08:00</published>
      <updated>2020-11-27T04:21:00+08:00</updated>
      <id>http://localhost:4000/windows%20%E4%B8%8B%E6%90%AD%E5%BB%BAlibtorch%E5%92%8Cpaddle%E7%9A%84C++%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA</id>
      <content type="html" xml:base="http://localhost:4000/windows-%E4%B8%8B%E6%90%AD%E5%BB%BAlibtorch%E5%92%8Cpaddle%E7%9A%84C++%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">&lt;blockquote&gt;
  &lt;p&gt;参考文章：&lt;a href=&quot;https://pytorch.org/cppdocs/installing.html&quot;&gt;NSTALLING C++ DISTRIBUTIONS OF PYTORCH&lt;/a&gt;，&lt;a href=&quot;https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc1/guides/05_inference_deployment/inference/windows_cpp_inference.html&quot;&gt;安装与编译 Windows 预测库&lt;/a&gt;，&lt;a href=&quot;https://pytorch.apachecn.org/docs/1.0/cpp_export.html&quot;&gt;在C++中加载PYTORCH模型&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;一-必要软件&quot;&gt;一. 必要软件&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://visualstudio.microsoft.com/zh-hans/vs/&quot;&gt;vs2019&lt;/a&gt;：paddle和torch这里的编译都是由Visual Studio 2019完成的&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pytorch.org/get-started/locally/&quot;&gt;libtorch&lt;/a&gt;：直接在官网上进行下载压缩包，这里说明下分为release和debug版本，直接下载release版本即可。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc1/guides/05_inference_deployment/inference/windows_cpp_inference.html&quot;&gt;paddle&lt;/a&gt;：这里选择2.0-rc1的cpu版本的直接进行解压安装。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://opencv.org/releases/&quot;&gt;opencv&lt;/a&gt;：windows下直接安装exe到本地即可。&lt;/li&gt;
  &lt;li&gt;cmake：直接用scoop安装&lt;code class=&quot;highlighter-rouge&quot;&gt;scoop install cmake&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二-安装libtorch环境&quot;&gt;二. 安装libtorch环境&lt;/h3&gt;

&lt;h4 id=&quot;21-构建一个c项目&quot;&gt;2.1 构建一个C++项目&lt;/h4&gt;

&lt;p&gt;目录层级如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;├─example-app
	 ├─build // 新建一个空目录
	 ├─CMakeLists.txt // 构建一个cmakelist
	 └─example-app.cpp // 构建一个cpp文件用于测试
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中，&lt;code class=&quot;highlighter-rouge&quot;&gt;CMakeList.txt&lt;/code&gt;具体设置如下：&lt;/p&gt;

&lt;div class=&quot;language-cmake highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cmake_minimum_required&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;VERSION 3.12 FATAL_ERROR&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;example-app&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# add CMAKE_PREFIX_PATH&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#增加opencv和libtorch的路径&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;APPEND CMAKE_PREFIX_PATH &lt;span class=&quot;s2&quot;&gt;&quot;D:/software/opencv/opencv/build/x64/vc15/lib&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# 注意这里如果是vs2015的版本，需要改成 /build/x64/vc14/lib&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;APPEND CMAKE_PREFIX_PATH &lt;span class=&quot;s2&quot;&gt;&quot;D:/software/libtorch&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;Torch REQUIRED&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;OpenCV REQUIRED&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;NOT Torch_FOUND&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;FATAL_ERROR &lt;span class=&quot;s2&quot;&gt;&quot;Pytorch Not Found!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;endif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;NOT Torch_FOUND&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;STATUS &lt;span class=&quot;s2&quot;&gt;&quot;Pytorch status:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;STATUS &lt;span class=&quot;s2&quot;&gt;&quot;    libraries: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TORCH_LIBRARIES&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;STATUS &lt;span class=&quot;s2&quot;&gt;&quot;OpenCV library status:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;STATUS &lt;span class=&quot;s2&quot;&gt;&quot;    version: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OpenCV_VERSION&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;STATUS &lt;span class=&quot;s2&quot;&gt;&quot;    libraries: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OpenCV_LIBS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;STATUS &lt;span class=&quot;s2&quot;&gt;&quot;    include path: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OpenCV_INCLUDE_DIRS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;nb&quot;&gt;add_executable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;example-app example-app.cpp&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;target_link_libraries&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;example-app &lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TORCH_LIBRARIES&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;OpenCV_LIBS&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;set_property&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;TARGET example-app PROPERTY CXX_STANDARD 11&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;C++测试代码（&lt;code class=&quot;highlighter-rouge&quot;&gt;example-app.cpp&lt;/code&gt;）如下（测试opencv和libtorch）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-C++&quot;&gt;#include &amp;lt;torch/torch.h&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;opencv2/core.hpp&amp;gt;
#include &amp;lt;opencv2/highgui/highgui.hpp&amp;gt;

using namespace std;
using namespace cv;

int main() {
  torch::Tensor tensor = torch::rand({2, 3});
  std::cout &amp;lt;&amp;lt; tensor &amp;lt;&amp;lt; std::endl;
  std::cout &amp;lt;&amp;lt; &quot;ok!&quot; &amp;lt;&amp;lt; std::endl;
  Mat img = imread(&quot;1.jpg&quot;);
  imshow(&quot;1&quot;,img);
  waitKey(0);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;22-编译和生成项目&quot;&gt;2.2 编译和生成项目&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;进入到&lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt;目录：&lt;code class=&quot;highlighter-rouge&quot;&gt;cd build&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;利用cmake进行编译： &lt;code class=&quot;highlighter-rouge&quot;&gt;cmake ..&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;编译顺利的话，就可以看到&lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt;目录下生成了如下所示：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gmaqn8ispmj30j706dq3s.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;利用vs2019打开项目&lt;code class=&quot;highlighter-rouge&quot;&gt;example-app.sln&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;点击&lt;code class=&quot;highlighter-rouge&quot;&gt;example-app&lt;/code&gt; 右键选择&lt;code class=&quot;highlighter-rouge&quot;&gt;设为启动项&lt;/code&gt;，并且将版本选择&lt;code class=&quot;highlighter-rouge&quot;&gt;release&lt;/code&gt;版本，点击&lt;code class=&quot;highlighter-rouge&quot;&gt;本地Windows调试器&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gmaqnkotpsj30kk0blmxs.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;23-调试问题的解决&quot;&gt;2.3 调试问题的解决&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;报错信息：&lt;code class=&quot;highlighter-rouge&quot;&gt;由于找不到c10.dll&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.dll&lt;/code&gt;这种找不到dll文件的，直接将dll文件(这些dll文件都在&lt;code class=&quot;highlighter-rouge&quot;&gt;libtorch/lib&lt;/code&gt;路径下)复制到&lt;code class=&quot;highlighter-rouge&quot;&gt;build/release&lt;/code&gt;文件夹下&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;opencv_world3411.dll&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;opencv_ffmpeg3411_64.dll&lt;/code&gt;等都在opencv的&lt;code class=&quot;highlighter-rouge&quot;&gt;opencv\opencv\build\x64\vc15\lib&lt;/code&gt;路径下。&lt;/li&gt;
  &lt;li&gt;这里注意测试opencv的时候，需要将图片放置到和&lt;code class=&quot;highlighter-rouge&quot;&gt;example-app.vcxproj&lt;/code&gt;同级目录下&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;24-exe生成文件的平台移植&quot;&gt;2.4 exe生成文件的平台移植&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;如果需要将生成的exe文件移植到其他PC上面，只需要将release文件夹下所有文件（包括dll文件和exe文件）复制到其他PC即可。&lt;/li&gt;
  &lt;li&gt;生成的exe文件在找图片的时候也是同级目录下找，因此需要将图片放置到&lt;code class=&quot;highlighter-rouge&quot;&gt;exe&lt;/code&gt;文件的同级目录下。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;25-pytorch模型在c平台的使用&quot;&gt;2.5 pytorch模型在C++平台的使用&lt;/h4&gt;

&lt;p&gt;PyTorch模型从Python到C++的转换由&lt;a href=&quot;https://pytorch.org/docs/master/jit.html&quot;&gt;Torch Script&lt;/a&gt;实现。Torch Script是PyTorch模型的一种表示，可由Torch Script编译器理解，编译和序列化。一般利用trace将PyTorch模型转换为Torch脚本,必须将模型的实例以及样本输入传递给&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.jit.trace&lt;/code&gt;函数。这将生成一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.jit.ScriptModule&lt;/code&gt;对象，并在模块的&lt;code class=&quot;highlighter-rouge&quot;&gt;forward&lt;/code&gt;方法中嵌入模型评估的跟踪。&lt;/p&gt;

&lt;h3 id=&quot;三-安装paddle的c环境&quot;&gt;三. 安装paddle的C++环境&lt;/h3&gt;

&lt;h4 id=&quot;31-下载安装paddle&quot;&gt;3.1 下载安装paddle&lt;/h4&gt;

&lt;p&gt;这里官网有2种方式在windows上安装paddle环境：一个是通过git下载paddle源码进行编译安装，另一种直接从官网下载zip编译好的文件（本文使用该种方式）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gmaqnvgko9j30q707iaac.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;32-结合paddleocr测试并使用paddle预测库&quot;&gt;3.2 结合paddleOCR测试并使用paddle预测库&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;paddleOCR的git地址：https://github.com/PaddlePaddle/PaddleOCR&lt;/li&gt;
  &lt;li&gt;下载到本地之后，&lt;code class=&quot;highlighter-rouge&quot;&gt;cd PaddleOCR\deploy\cpp_infer&lt;/code&gt;，修改&lt;code class=&quot;highlighter-rouge&quot;&gt;CMakeList.txt&lt;/code&gt;文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cmake highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;SET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;PADDLE_LIB &lt;span class=&quot;s2&quot;&gt;&quot;D:/software/paddle_inference_install_dir&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 这里是下载的paddle预测库的路径&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;SET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;OPENCV_DIR &lt;span class=&quot;s2&quot;&gt;&quot;D:/software/opencv/opencv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 这里是下载的opencv的路径&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;find_package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;OpenCV REQUIRED&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;新建一个build文件夹：&lt;code class=&quot;highlighter-rouge&quot;&gt;mkdir build&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;进入build：&lt;code class=&quot;highlighter-rouge&quot;&gt;cd build&lt;/code&gt; ， 编译：&lt;code class=&quot;highlighter-rouge&quot;&gt;cmake ..&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;同样的利用vs2019打开项目&lt;code class=&quot;highlighter-rouge&quot;&gt;ocr_system.sln&lt;/code&gt;，生成即可。&lt;/li&gt;
  &lt;li&gt;这里注意需要将&lt;code class=&quot;highlighter-rouge&quot;&gt;paddle_fluid.dll&lt;/code&gt;放入到&lt;code class=&quot;highlighter-rouge&quot;&gt;Release&lt;/code&gt;目录下。&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="pytorch" />
      
        <category term="paddle" />
      
        <category term="C++" />
      
        <category term="deeplearning" />
      

      
        <summary type="html">介绍在C++平台下搭建torch和paddle的环境</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">GCN在多标签分类中的应用</title>
      <link href="http://localhost:4000/GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8" rel="alternate" type="text/html" title="GCN在多标签分类中的应用" />
      <published>2020-11-27T04:21:00+08:00</published>
      <updated>2020-11-27T04:21:00+08:00</updated>
      <id>http://localhost:4000/GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8</id>
      <content type="html" xml:base="http://localhost:4000/GCN%E5%9C%A8%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8">&lt;h3 id=&quot;一--torch的图神经网络库pyg&quot;&gt;一.  Torch的图神经网络库pyG&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;torch_geometric 官方文档：https://pytorch-geometric.readthedocs.io/en/latest/index.html&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;11-安装及使用&quot;&gt;1.1 安装及使用&lt;/h4&gt;

&lt;p&gt;这里参考官网的安装过程。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;确定自己安装的pytorch版本：&lt;code class=&quot;highlighter-rouge&quot;&gt;pip list&lt;/code&gt;进行查看，例如本人的torch版本为&lt;code class=&quot;highlighter-rouge&quot;&gt;1.6.0+cu101&lt;/code&gt;（这里的&lt;code class=&quot;highlighter-rouge&quot;&gt;cu101&lt;/code&gt;是指cuda10.1）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装相关的第三方包，这里注意要匹配上面的torch版本，因此：&lt;code class=&quot;highlighter-rouge&quot;&gt;${TORCH} = 1.6.0&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;${CUDA} = cu101&lt;/code&gt;&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install &lt;span class=&quot;nt&quot;&gt;--no-index&lt;/span&gt; torch-scatter &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://pytorch-geometric.com/whl/torch-&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TORCH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;+&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CUDA&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.html
pip install &lt;span class=&quot;nt&quot;&gt;--no-index&lt;/span&gt; torch-sparse &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://pytorch-geometric.com/whl/torch-&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TORCH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;+&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CUDA&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.html
pip install &lt;span class=&quot;nt&quot;&gt;--no-index&lt;/span&gt; torch-cluster &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://pytorch-geometric.com/whl/torch-&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TORCH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;+&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CUDA&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.html
pip install &lt;span class=&quot;nt&quot;&gt;--no-index&lt;/span&gt; torch-spline-conv &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; https://pytorch-geometric.com/whl/torch-&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TORCH&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;+&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CUDA&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.html
pip install torch-geometric
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安装完成之后，测试下&lt;code class=&quot;highlighter-rouge&quot;&gt;import torch_geometric&lt;/code&gt;导包没有报错说明安装完成了。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;12-图数据导入&quot;&gt;1.2 图数据导入&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;torch_geometric.data&lt;/em&gt;&lt;/strong&gt;这个模块包含了一个叫Data的类，而这个类可以很方便的构建属于自己的数据集。&lt;code class=&quot;highlighter-rouge&quot;&gt;data&lt;/code&gt;实例有以下属性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;：节点的特征矩阵，shape = [节点个数，节点的特征数]。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;edge_index&lt;/code&gt;：这里可以理解为图的邻接矩阵，但是要注意这里要将邻接矩阵转换成COO格式，shape = [2, 边的数量]，type = torch.long。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;edge_attr&lt;/code&gt;：边的特征矩阵，shape = [边的个数，边的特征数]&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;：标签，如果任务是图分类，shape = [1, 图的标签数]；如果是节点分类，shape = [节点个数，节点的标签数]。（这里注意一哈：在torch中如果是多分类任务，不用转成onehot形式哦，因此标签数为1）&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;is_directed()&lt;/code&gt;：是否是有向图&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(1) 下面是edge_index的具体从邻接矩阵生成COO模式的代码。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.sparse&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coo_matrix&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 转化成COO格式&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coo_A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coo_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adj_arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coo_A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coo_A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(2) 构建自己的数据集，只需要用list来封装这些Data即可。具体代码如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;13-图数据的转换及展示&quot;&gt;1.3 图数据的转换及展示&lt;/h4&gt;

&lt;p&gt;我们可以利用&lt;a href=&quot;https://pypi.org/project/networkx/&quot;&gt;networkx&lt;/a&gt;来对Data这个图进行展示和转换成networkx的图结构。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch_geometric.utils.convert&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_networkx&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;networkx&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_networkx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write_gexf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test.gexf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;同时，还可以将gexf格式的图数据文件经过&lt;a href=&quot;https://gephi.org/users/download/&quot;&gt;Gephi&lt;/a&gt;这个开源的图数据展示软件来进行节点的渲染。&lt;/p&gt;

&lt;h3 id=&quot;二-图卷积网络gcn在多标签分类中的应用&quot;&gt;二. 图卷积网络GCN在多标签分类中的应用&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;论文参考：&lt;a href=&quot;https://arxiv.org/abs/1609.02907&quot;&gt;Semi-Supervised Classification with Graph Convolutional Networks&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;21-gcn在模型应用上的优缺点&quot;&gt;2.1 GCN在模型应用上的优缺点。&lt;/h4&gt;

&lt;p&gt;本次探究的是图卷积网络在图分类（多标签）上的应用，因此不涉及到节点的分类任务。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GCN的优点&lt;/strong&gt;：可以捕捉图的全局信息，很好的表征节点的特征，边的特征。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GCN的缺点&lt;/strong&gt;：若是新增节点，整个图发生变化， 那么GCN的结构就会发生变化。因此对于节点不固定的图结构来说，不适用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GCN的主要作用&lt;/strong&gt;：抽取图中节点的拓扑信息（节点的邻接信息）。这里学到的是每个节点的一个唯一确定的embedding。如下图所示，多层的GCN抽取的是每个节点的唯一确定的embedding。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/008eGmZEgy1gmugxnmbmhj30aw055aag.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GCN的特性&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;局部参数共享，算子是适用于每个节点（圆圈代表算子），处处共享。&lt;/li&gt;
  &lt;li&gt;感受域正比于层数，最开始的时候，每个节点包含了直接邻居的信息，再计算第二层时就能把邻居的邻居的信息包含进来，这样参与运算的信息就更多更充分。层数越多，感受域就更广，参与运算的信息就更多。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;22-gcn在图分类的模型搭建&quot;&gt;2.2 GCN在图分类的模型搭建&lt;/h4&gt;

&lt;p&gt;图分类任务下的模型搭建过程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/008eGmZEgy1gmugybl0ydj30k00b7gm2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此，利用pytorch_geometric来搭建图分类任务（多标签）的模型。这里代码中引入了两次图卷积和池化。在输入的数据中，除了包含节点的特征，还包含了边的特征。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch_geometric.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GraphConv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TopKPooling&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch_geometric.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;global_mean_pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gap&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch_geometric.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;global_max_pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gmp&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multi_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GraphConv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# self.conv1.weight.data.normal_()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TopKPooling&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GraphConv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TopKPooling&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multi_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge_attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lin3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;23-多标签multi-label分类任务&quot;&gt;2.3 多标签（Multi-Label）分类任务&lt;/h4&gt;

&lt;p&gt;在多标签分类任务中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;输入的y：shape = [batch_size, multi-label的个数]，其中multi-label的形式都是[0,1,0,0,1….]，即每个类别之间都互不影响，且结果只有0和1。这里在&lt;code class=&quot;highlighter-rouge&quot;&gt;torch_geometric.data.y&lt;/code&gt;的shape = [1,multi-label的个数]。&lt;/li&gt;
  &lt;li&gt;分类模型的最后一层激活函数：&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.sigmoid()&lt;/code&gt;函数（即二分类常用的激活函数）,这里对于多标签分类任务同样适用。&lt;/li&gt;
  &lt;li&gt;损失函数的定义：&lt;code class=&quot;highlighter-rouge&quot;&gt; torch.nn.BCELoss()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;准确率的定义：在训练的时候，一般除了看训练集和验证集的loss以外，acc其实也可以当作模型好坏的指标。但是对于多标签分类而言，这里和一般的多分类，二分类任务定义的准确率不太一样。个人的理解（可能不对蛤）：对于一个样本（多标签）而言，有且仅有每个标签都预测对了，这个样本才能算预测正确了，因此，定义了以下acc。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc_thread&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="pytorch" />
      
        <category term="GCN" />
      
        <category term="图算法" />
      
        <category term="deeplearning" />
      

      
        <summary type="html">介绍在图卷积网络在多标签分类任务中的应用</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">pytorch使用YOLOv5训练数据</title>
      <link href="http://localhost:4000/pytorch%E4%BD%BF%E7%94%A8YOLOv5%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE" rel="alternate" type="text/html" title="pytorch使用YOLOv5训练数据" />
      <published>2020-10-27T03:21:00+08:00</published>
      <updated>2020-10-27T03:21:00+08:00</updated>
      <id>http://localhost:4000/pytorch%E4%BD%BF%E7%94%A8YOLOv5%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE</id>
      <content type="html" xml:base="http://localhost:4000/pytorch%E4%BD%BF%E7%94%A8YOLOv5%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE">&lt;h3 id=&quot;一-需要下载的资源&quot;&gt;一. 需要下载的资源&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Fork 下官方的开源项目：https://github.com/ultralytics/yolov5&lt;/li&gt;
  &lt;li&gt;git clone 下Fork之后的项目到自己本地仓库中。&lt;/li&gt;
  &lt;li&gt;采用的训练集（简单的，仅有一个类）：源自&lt;a href=&quot;https://www.kaggle.com/c/global-wheat-detection/data&quot;&gt;Kaggle的小麦数据集&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;如果有gpu的话，最好安装cuda进行训练加速，这里可以参考本人的另一篇文章：&lt;a href=&quot;https://yy2lyx.github.io/Windows10%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%90%AD%E5%BB%BACUDA10.1%E5%92%8Cpytorch1.6/&quot;&gt;Windows10环境下搭建CUDA10.1和pytorch1.6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二--构建属于自己的目标检测模型&quot;&gt;二 . 构建属于自己的目标检测模型&lt;/h3&gt;

&lt;h4 id=&quot;21-在官网的开源yolo5项目的基础上进行构建&quot;&gt;2.1 在官网的开源yolo5项目的基础上进行构建&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;git 克隆到本地仓库：&lt;code class=&quot;highlighter-rouge&quot;&gt;git clone https://github.com/xx/yolov5.git&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;进入项目中，并安装需要的第三方依赖：&lt;code class=&quot;highlighter-rouge&quot;&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;新建一个原始数据的目录：：&lt;code class=&quot;highlighter-rouge&quot;&gt;mkdir ori_data&lt;/code&gt;，将下载好的小麦数据集解压后放到项目。&lt;/li&gt;
  &lt;li&gt;创建输出一个文件输出目录：&lt;code class=&quot;highlighter-rouge&quot;&gt;mkdir wheat_data&lt;/code&gt;，并在此目录下新建以下目录，如下图所示
    &lt;div class=&quot;language-js highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;├─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;images&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;│&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;├─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;train&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;│&lt;/span&gt;  &lt;span class=&quot;err&quot;&gt;└─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;└─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;labels&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;├─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;train&lt;/span&gt;
  &lt;span class=&quot;err&quot;&gt;└─&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;val&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;构建数据集，新建一个&lt;code class=&quot;highlighter-rouge&quot;&gt;munge_data.py&lt;/code&gt;文件&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ast&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;shutil&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ori_data'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'wheat_data'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterrows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'image_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;bounding_boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bounding_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;# 这里需要将图像数据归一化处理（yolo需要的输入为归一化后的数据,且为浮点数）&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_center&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1024.0&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_center&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_center&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# 保存bbox的图片信息&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savetxt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'labels/{data_type}/{image_name}.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;yolo_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;fmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;# 将目标图片文件保存到指定文件中&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shutil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copyfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train/{image_name}.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'images/{data_type}/{image_name}.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 将string of list 转成list数据&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;literal_eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 利用groupby 将同一个image_id的数据进行聚合，方式为list进行，并且用reset_index直接转变成dataframe&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'image_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 划分数据集&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# 重设 index （这里数据被打乱，index改变混乱）&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;process_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;process_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'val'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;运行构建数据的py文件：&lt;code class=&quot;highlighter-rouge&quot;&gt;python munge_data.py&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里可以看到在输出结果目录中，放入了需要的整理后的数据集&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新建一个&lt;code class=&quot;highlighter-rouge&quot;&gt;wheat.yaml&lt;/code&gt;yaml文件，指定模型训练时候的输入及其类别（注意这里冒号后面要加空格，yamal格式问题）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wheat_data/images/train // 指定训练目录&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wheat_data/images/val // 指定验证目录&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;nc&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;1 // 指定类别&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;wheat&quot;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;s&quot;&gt;// 指定类别名字&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;进行模型训练：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 train.py &lt;span class=&quot;nt&quot;&gt;--img&lt;/span&gt; 1024 &lt;span class=&quot;nt&quot;&gt;--batch&lt;/span&gt; 8 &lt;span class=&quot;nt&quot;&gt;--epoch&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--data&lt;/span&gt; wheat.yaml &lt;span class=&quot;nt&quot;&gt;--cfg&lt;/span&gt; .&lt;span class=&quot;se&quot;&gt;\m&lt;/span&gt;odels&lt;span class=&quot;se&quot;&gt;\y&lt;/span&gt;olov5s.yaml &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; wm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;这里可能会报错（Dataloader中设置了多进程导致的），报错信息如下所示：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;File &lt;span class=&quot;s2&quot;&gt;&quot;C:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\s&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;oft&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\p&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ython3.7.9&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\l&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ib&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\m&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;ultiprocessing&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;eduction.py&quot;&lt;/span&gt;, line 60, &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;dump     
ForkingPickler&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;file, protocol&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;.dump&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;obj&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; BrokenPipeError: &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Errno 32] Broken pipe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里可以参考文章：https://github.com/pytorch/pytorch/issues/2341。解决方案：将&lt;code class=&quot;highlighter-rouge&quot;&gt;utils\datasets.py&lt;/code&gt;文件中&lt;code class=&quot;highlighter-rouge&quot;&gt;num_workers&lt;/code&gt;改成0即可（代码第68行）。训练完成后如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gk47ziddqvj30jg01vt8i.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以查看本地tensorboard训练过程：&lt;code class=&quot;highlighter-rouge&quot;&gt;tensorboard --logdir=runs&lt;/code&gt;，如果这里出现问题，可以换成一下命令：&lt;code class=&quot;highlighter-rouge&quot;&gt;python -m tensorboard.main --logdir logs&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/0081Kckwgy1gk4804vrrkj310d0gajt5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这里还可以使用coco数据集的&lt;a href=&quot;https://drive.google.com/drive/folders/1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J&quot;&gt;预训练模型&lt;/a&gt;进行训练，可能效果会更好&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 train.py &lt;span class=&quot;nt&quot;&gt;--img&lt;/span&gt; 1024 &lt;span class=&quot;nt&quot;&gt;--batch&lt;/span&gt; 8 &lt;span class=&quot;nt&quot;&gt;--epoch&lt;/span&gt; 100 &lt;span class=&quot;nt&quot;&gt;--data&lt;/span&gt; wheat.yaml &lt;span class=&quot;nt&quot;&gt;--cfg&lt;/span&gt; .&lt;span class=&quot;se&quot;&gt;\m&lt;/span&gt;odels&lt;span class=&quot;se&quot;&gt;\y&lt;/span&gt;olov5s.yaml &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; wm &lt;span class=&quot;nt&quot;&gt;--weights&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将训练好的模型放到当前文件夹下：&lt;code class=&quot;highlighter-rouge&quot;&gt;cp runs/exp0_wm/weights/best.pt . &lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;选择测试图片的文件夹进行生成测试：&lt;code class=&quot;highlighter-rouge&quot;&gt;python detect.py --source ./test_data --weights best.pt &lt;/code&gt;，这里可以看到新生成一个文件夹&lt;code class=&quot;highlighter-rouge&quot;&gt;inference/output&lt;/code&gt;中就是测试后标记bbox后的图片。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="pytorch" />
      
        <category term="YOLOv5" />
      
        <category term="deeplearning" />
      

      
        <summary type="html">介绍如何利用官方开源的Yolov5训练一个属于自己的模型</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">面试总结</title>
      <link href="http://localhost:4000/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93" rel="alternate" type="text/html" title="面试总结" />
      <published>2020-06-12T23:21:00+08:00</published>
      <updated>2020-06-12T23:21:00+08:00</updated>
      <id>http://localhost:4000/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93</id>
      <content type="html" xml:base="http://localhost:4000/%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93">&lt;blockquote&gt;
  &lt;p&gt;面试官会根据自己简历中提到的一些点进行提问，这里先自己对某些点进行深挖。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;一数据处理&quot;&gt;一.数据处理&lt;/h3&gt;
&lt;p&gt;海量数据：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;（1）数据量太大，无法短时间内处理完成&lt;/li&gt;
  &lt;li&gt;（2）无法一次性将数据放入内存中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;11-缺失值处理&quot;&gt;1.1 缺失值处理&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;填充固定值：选取某个固定值/默认值填充缺失值。&lt;/li&gt;
  &lt;li&gt;填充均值：对每一列的缺失值，填充当列的均值。&lt;/li&gt;
  &lt;li&gt;填充中位数：对每一列的缺失值，填充当列的中位数。&lt;/li&gt;
  &lt;li&gt;填充众数：对每一列的缺失值，填充当列的众数。由于存在某列缺失值过多，众数为nan的情况，因此这里取的是每列删除掉nan值后的众数。&lt;/li&gt;
  &lt;li&gt;填充上下条的数据：对每一条数据的缺失值，填充其上下条数据的值。&lt;/li&gt;
  &lt;li&gt;填充插值得到的数据：用插值法拟合出缺失的数据，然后进行填充。插值是离散函数逼近的重要方法，利用它可通过函数在有限个点处的取值状况，估算出函数在其他点处的近似值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二机器学习&quot;&gt;二.机器学习&lt;/h3&gt;
&lt;h4 id=&quot;21--svm和lr的区别与联系&quot;&gt;2.1  SVM和LR的区别与联系？&lt;/h4&gt;
&lt;p&gt;SVM 和 LR 都是属于分类算法，不过 SVM 是通过划分超平面的方法来进行分类，而 LR 则是通过计算样本属于哪个类别的概率，从而达到分类效果&lt;/p&gt;

&lt;h4 id=&quot;22--交叉熵函数系列问题与最大似然函数的关系和区别&quot;&gt;2.2  交叉熵函数系列问题？与最大似然函数的关系和区别？&lt;/h4&gt;
&lt;p&gt;在二分类中，交叉熵函数和负最大似然函数的表达式是相同的，但是交叉熵函数是从信息论角度得到的，而最大似然函数则是从概率论角度得到的&lt;/p&gt;

&lt;p&gt;交叉熵涉及到2点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;信息量：假设X是一个离散型随机变量，其取值集合为X，概率分布函数为p(x)=Pr(X=x),x∈X，我们定义事件X=x0的信息量为：
I(x0)=−log(p(x0))，可以理解为，一个事件发生的概率越大，则它所携带的信息量就越小，而当p(x0)=1时，熵将等于0，也就是说该事件的发生不会导致任何信息量的增加。举个例子，小明平时不爱学习，考试经常不及格，而小王是个勤奋学习的好学生，经常得满分，所以我们可以做如下假设：
事件A：小明考试及格，对应的概率P(xA)=0.1，信息量为I(xA)=−log(0.1)=3.3219
事件B：小王考试及格，对应的概率P(xB)=0.999，信息量为I(xB)=−log(0.999)=0.0014
可以看出，结果非常符合直观：小明及格的可能性很低(十次考试只有一次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高。&lt;/li&gt;
  &lt;li&gt;熵：假设小明的考试结果是一个0-1分布XA只有两个取值{0：不及格，1：及格}，在某次考试结果公布前，小明的考试结果有多大的不确定度呢？你肯定会说：十有八九不及格！因为根据先验知识，小明及格的概率仅有0.1,90%的可能都是不及格的。怎么来度量这个不确定度？求期望！不错，我们对所有可能结果带来的额外信息量求取均值（期望），其结果不就能够衡量出小明考试成绩的不确定度了吗。&lt;strong&gt;熵其实是信息量的期望值，它是一个随机变量的确定性的度量。熵越大，变量的取值越不确定，反之就越确定。&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;相对熵：称为&lt;strong&gt;KL散度&lt;/strong&gt;，是两个随机分布间距离的度量。越小说明分布越一致。&lt;/li&gt;
  &lt;li&gt;交叉熵：交叉熵与KL距离在行为上是等价的，都反映了分布p，q的相似程度。特别的，在logistic regression中，
p:真实样本分布，服从参数为p的0-1分布，即X∼B(1,p)X∼B(1,p)
q:待估计的模型，服从参数为q的0-1分布，即X∼B(1,q)两者的交叉熵为&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三-nlp&quot;&gt;三. NLP&lt;/h3&gt;
&lt;h4 id=&quot;31--什么是tf-idf&quot;&gt;3.1  什么是TF-IDF?&lt;/h4&gt;
&lt;p&gt;词频-逆文档频率TF-IDF(term frequency–inverse document frequency)是一种用于信息检索与数据挖掘的常用加权技术，常用于挖掘文章中的关键词，而且算法简单高效，常被工业用于最开始的文本数据清洗。&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\text { 词频(TF) }=\frac{\text { 某个词在文章中的出现次数 }}{\text { 文章的总词数 }}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\text { 逆文档频率(IDF) }=\log \left(\frac{\text { 语料库的文档总数 }}{\text { 包含该词的文档数 } x+1}\right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;当有TF(词频)和IDF(逆文档频率)后，将这两个词相乘，就能得到一个词的TF-IDF的值。某个词在文章中的TF-IDF越大，那么一般而言这个词在这篇文章的重要性会越高，所以通过计算文章中各个词的TF-IDF，由大到小排序，排在最前面的几个词，就是该文章的关键词。&lt;/p&gt;

&lt;h4 id=&quot;32--什么是word2vec&quot;&gt;3.2  什么是word2vec&lt;/h4&gt;

&lt;p&gt;判断一个词的词性（动词，名词）这里可以用word2vec，&lt;/p&gt;

&lt;p&gt;嵌入到一个数学空间里，这种嵌入方式，就叫词嵌入（word embedding)，而 Word2vec是词嵌入的一种。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Skip-gram 模型：用一个词语作为输入，来预测它周围的上下文&lt;/li&gt;
  &lt;li&gt;CBOW 模型：拿一个词语的上下文作为输入，来预测这个词语本身&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;33--fasttext&quot;&gt;3.3  fastText&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;word2vec的CBOW模型架构和fastText模型非常相似&lt;/li&gt;
  &lt;li&gt;fastText 和CBOW差别：CBOW的输入是目标单词的上下文，fastText的输入是多个单词及其n-gram特征，这些特征用来表示单个文档；CBOW的输入单词被onehot编码过，fastText的输入特征是被embedding过；CBOW的输出是目标词汇，fastText的输出是文档对应的类标。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;34--ner&quot;&gt;3.4  NER&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;named-entity-recognition（命名实体识别，又叫“专名识别”）。指识别文本中具有特定意义的实体，主要包括人名，地名，机构名，专有名词。&lt;strong&gt;NER系统就是从非结构化的输入文本中抽取出上述实体，并且可以按照业务需求识别出更多类别的实体&lt;/strong&gt;，比如产品名称、型号、价格等。学术上NER所涉及的命名实体一般包括3大类（实体类，时间类，数字类）和7小类（人名、地名、组织机构名、时间、日期、货币、百分比）。货币、百分比等数字类实体可通过正则搞定。&lt;/li&gt;
  &lt;li&gt;NER是NLP中一项基础性关键任务。&lt;strong&gt;从自然语言处理的流程来看，NER可以看作词法分析中未登录词识别的一种，是未登录词中数量最多、识别难度最大、对分词效果影响最大问题。&lt;/strong&gt;同时NER也是关系抽取、事件抽取、知识图谱、机器翻译、问答系统等诸多NLP任务的基础。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;原句：姚明在NBA打篮球&lt;/p&gt;

  &lt;p&gt;如下标签：姚/B-PER 明/I-PER 在/O NBA/B_ORG 打/O 篮/O 球/O&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;其中常见的方法是对字或者词打上标签。&lt;code class=&quot;highlighter-rouge&quot;&gt;B-type&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;I-type&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;O&lt;/code&gt;， 其中&lt;code class=&quot;highlighter-rouge&quot;&gt;B-type&lt;/code&gt;表示组成该类型实体的第一个字或词。&lt;code class=&quot;highlighter-rouge&quot;&gt;I-type&lt;/code&gt;表示组成该类型实体的中间或最后字或词，&lt;code class=&quot;highlighter-rouge&quot;&gt;O&lt;/code&gt;表示该字或词不组成命名实体，当然有的地方也采用&lt;code class=&quot;highlighter-rouge&quot;&gt;B-type&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;I-type&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;E-type&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;O&lt;/code&gt;形式。&lt;/p&gt;

&lt;p&gt;整体结构如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;字（词嵌入）==&amp;gt; BiLSTM（拿到字的每一个标签的所有得分）==&amp;gt; CRF（输出预测标签值）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;这里问什么要用到CRF(直接用全连接分类即可)？==&amp;gt; &lt;strong&gt;CRF层能从训练数据中获得约束性的规则&lt;/strong&gt;：CRF层可以为最后预测的标签添加一些约束来保证预测的标签是合法的。在训练数据训练过程中，这些约束可以通过CRF层自动学习到。 这些约束可以是： I：句子中第一个词总是以标签“B-“ 或 “O”开始，而不是“I-” II：标签“B-label1 I-label2 I-label3 I-…”,label1, label2, label3应该属于同一类实体。例如，“B-Person I-Person” 是合法的序列, 但是“B-Person I-Organization” 是非法标签序列. III：标签序列“O I-label” is 非法的.实体标签的首个标签应该是 “B-“ ，而非 “I-“, 换句话说,有效的标签序列应该是“O B-label”。 有了这些约束，标签序列预测中非法序列出现的概率将会大大降低。&lt;/li&gt;
  &lt;li&gt;CRF（条件随机场）：属于判别式模型，条件随机场对多个变量在给定观测值后的条件概率进行建模。概率图模型是以某些可观测的变量为条件分布进行推断。假设某个字的前后（&lt;script type=&quot;math/tex&quot;&gt;x_{1}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;x_{2}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;x_{3}&lt;/script&gt;）,推断问题的目标就是计算2在1的条件下发生的概率，然后所有条件概率相加。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;35--文本增强技术&quot;&gt;3.5  文本增强技术&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;词汇和短语进行替换&lt;/strong&gt;：选择同义词进行替换；空间中找到相邻的词汇进行替换；利用TF-IDF对哪些非核心词汇（分值很低的）进行替换&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;随机噪音&lt;/strong&gt;：随机插入一些词汇，占位符；交换词汇或者shuffle句子；随机删除词汇或者句子&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;混合增强&lt;/strong&gt;：起源于图像的mixup（猫和狗的混合）。提出了wordMixup和sentMixup将词向量和句向量进行Mixup。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;回译&lt;/strong&gt;：中文翻译成英文表达，然后再由英文翻译回中文。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GAN对抗生成网络&lt;/strong&gt;：GAN 主要分为两部分：生成模型和判别模型。生成模型的作用是模拟真实数据的分布，判别模型的作用是判断一个样本是真实的样本还是生成的样本。GAN 的目标是训练一个生成模型完美的拟合真实数据分布使得判别模型无法区分。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;四-图像算法&quot;&gt;四. 图像算法&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;参考文章：
&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80852438&quot;&gt;图像总常用的变换&lt;/a&gt;
&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59640437&quot;&gt;边缘检测&lt;/a&gt;
&lt;a href=&quot;https://blog.csdn.net/samkieth/article/details/49533435&quot;&gt;图像增强技术&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;41--图像特征提取的方法有哪些&quot;&gt;4.1  图像特征提取的方法有哪些？&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;SIFT（尺度不变特征变换）—— 图像拼接：&lt;/li&gt;
  &lt;li&gt;HOG（方向梯度直方图（Histogram of Oriented Gradient, HOG））—— 行人检测：特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。）&lt;strong&gt;本质：梯度的统计信息，而梯度主要存在于边缘的地方&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;LBP(Local Binary Pattern局部二值模式)：种描述图像局部纹理的特征算子，具有旋转不变性与灰度不变性等显著优点。LBP特征将窗口中心点与邻域点的关系进行比较，重新编码形成新特征以消除对外界场景对图像的影响，因此一定程度上解决了复杂场景下（光照变换）特征描述问题（&lt;strong&gt;局部纹理特征提取&lt;/strong&gt;）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;42--为什么要图像的灰度化&quot;&gt;4.2  为什么要图像的灰度化?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;图像识别中要识别物体：找到edge ==&amp;gt; 计算梯度 ==&amp;gt; 需要用到灰度图&lt;/li&gt;
  &lt;li&gt;有利于图像特征提取：RGB采用的是三通道，而灰度图用的是单通道，能加快特征抽取。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;43--为什么预处理中要归一化和标准化&quot;&gt;4.3  为什么预处理中要归一化和标准化&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;取值范围从0～255已经转化为0～1之间了，这个对于后续的神经网络或者卷积神经网络处理有很大的好处，加快梯度下降求解的速度&lt;/li&gt;
  &lt;li&gt;减小了几何变换和仿射变化的影响。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;44--为什么要中值滤波和均值滤波&quot;&gt;4.4  为什么要中值滤波和均值滤波?&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;目的：消除图像中的噪声成分叫作图像的平滑化或滤波操作。图像的能量大部分集中在幅度谱的低频和中频段是很常见的，而在较高频段，感兴趣的信息经常被噪声淹没。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;中值滤波：一连串数字｛1，4，6，8，9｝中，数字6就是这串数字的中值.椒盐噪声很好的被平滑了，而且也没均值那样模糊化太过于严重。&lt;/li&gt;
  &lt;li&gt;均值滤波：图片中一个方块区域（一般为3*3）内，中心点的像素为全部点像素值的平均值。一般均值滤波过于模糊化了。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;45--边缘检测算子&quot;&gt;4.5  边缘检测算子&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Roberts算子：基于x轴和y轴的&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
s_{x}=\left[\begin{array}{cc}
1 &amp; 0 \\
0 &amp; -1
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
s_{y}=\left[\begin{array}{cc}
0 &amp; -1 \\
1 &amp; 0
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Prewitt算子：&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
s_{x}=\left[\begin{array}{ccc}
-1 &amp; 0 &amp; 1 \\
-1 &amp; 0 &amp; 1 \\
-1 &amp; 0 &amp; 1
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
s_{y}=\left[\begin{array}{ccc}
1 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 \\
-1 &amp; -1 &amp; -1
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Sobel算子：&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
s_{x}=\left[\begin{array}{ccc}
-1 &amp; 0 &amp; 1 \\
-2 &amp; 0 &amp; 2 \\
-1 &amp; 0 &amp; 1
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
s_{y}=\left[\begin{array}{ccc}
1 &amp; 2 &amp; 1 \\
0 &amp; 0 &amp; 0 \\
-1 &amp; -2 &amp; -1
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基本的边缘算子&lt;/strong&gt;如Sobel求得的边缘图存在很多问题，如&lt;strong&gt;噪声污染没有被排除、边缘线太过于粗宽&lt;/strong&gt;等&lt;/li&gt;
  &lt;li&gt;Canny算子：目标是找到一个最优的边缘。具有以下优势
    &lt;ul&gt;
      &lt;li&gt;低错误率：标识尽可能多的实际边缘，剑豪噪声产生的误报。&lt;/li&gt;
      &lt;li&gt;高定位性：标识出的边缘要与图像的实际边缘尽可能的接近。&lt;/li&gt;
      &lt;li&gt;最小响应：图像中的边缘只能标识一次。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;canny检测的步骤：
    &lt;ul&gt;
      &lt;li&gt;
        &lt;ol&gt;
          &lt;li&gt;使用高斯滤波器降噪。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;ol&gt;
          &lt;li&gt;利用Sobel算子进行卷积（x和y反向）&lt;/li&gt;
          &lt;li&gt;将像素点上x和y卷积之后的平方求根，并计算x，y方向上的角度，&lt;script type=&quot;math/tex&quot;&gt;G=\sqrt{G_{x}^{2}+G_{y}^{2}}&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;\theta=\arctan \left(\frac{G_{y}}{G_{x}}\right)&lt;/script&gt;&lt;/li&gt;
          &lt;li&gt;非极大值抑制，进一步排除非边缘的像素，仅保留一些细线条。&lt;/li&gt;
          &lt;li&gt;滞后阈值：高于某阈值，保留为边缘像素，反之排除。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;46--常用的插值方法&quot;&gt;4.6  常用的插值方法&lt;/h4&gt;

&lt;p&gt;在图像几何变换时，无法给有些像素点直接赋值，例如，&lt;strong&gt;将图像放大两倍，必然会多出一些无法被直接映射的像素点，对于这些像素点，通过插值决定它们的值&lt;/strong&gt;。于是，产生了图像插值算法。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;线性插值：&lt;strong&gt;最近邻插值，双线性插值以及双三次插值等&lt;/strong&gt;，&lt;script type=&quot;math/tex&quot;&gt;f(x)=a_{1} x+a_{0}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;47-深度学习和传统目标检测方法的优缺点&quot;&gt;4.7 深度学习和传统目标检测方法的优缺点&lt;/h4&gt;

&lt;p&gt;传统的目标检测算法对光照，明暗，数据传输，物体遮挡等上模型的鲁棒性不强。&lt;/p&gt;

&lt;h4 id=&quot;48--图像增强技术&quot;&gt;4.8  图像增强技术&lt;/h4&gt;

&lt;p&gt;增强技术也可以有多种分类，如，可以分为平滑（抑制高频成分）与锐化（增强高频成分），空间域与频域。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;空间域增强就是指增强构成图像的像素，是直接对这些像素进行操作的过程。&lt;/li&gt;
  &lt;li&gt;频域则是修改图像的傅立叶变换。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;49-ssd和yolo&quot;&gt;4.9 SSD和Yolo&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;SSD：将物体检测这个问题的解空间，抽象为一组预先设定好（尺度，长宽比）的bounding box。在每个bounding box，预测分类label，以及box offset来更好的框出物体。对一张图片，结合多个大小不同的feature map的预测结果，以期能够处理大小不同的物体。
    &lt;ul&gt;
      &lt;li&gt;（优点）相比Fast RNN系列，删除了bounding box proposal这一步，及后续的重采样步骤，因而速度较快，达到59FPS。&lt;/li&gt;
      &lt;li&gt;（优点）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;YOLO：&lt;strong&gt;将物体检测这个问题定义为bounding box和分类置信度的回归问题。&lt;/strong&gt;将整张图像作为输入，划分成SxS grid，每个cell预测B个bounding box（x, y, w, h）及对应的分类置信度（class-specific confidence score）。分类置信度是bounding box是物体的概率及其与真实值IOU相乘的结果。
    &lt;ul&gt;
      &lt;li&gt;（优点）速度快，45FPS&lt;/li&gt;
      &lt;li&gt;（优点）YOLO使用图像的全局信息做预测，因而对背景的误识别率低。&lt;/li&gt;
      &lt;li&gt;（缺点） 每个cell只能拥有一个label和两个bounding box，这个空间局限性，使得对小物体检测效果不好&lt;/li&gt;
      &lt;li&gt;（缺点）对于物体长宽比的泛化能力较弱，当一类物体新的长宽比出现时，检测准确率减低。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;二者之间的差别：YOLO在卷积层后接全连接层，即检测时只利用了最高层Feature maps（包括Faster RCNN也是如此）而SSD采用金字塔结构，即利用了conv4-3/fc7/conv6-2/conv7-2/conv8_2/conv9_2这些大小不同的feature maps，在多个feature maps上同时进行softmax分类和位置回归。SSD还加入了Prior box&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;410--零样本学习zero-shot-learning和单样本学习one-shot-learning&quot;&gt;4.10  零样本学习（Zero-shot Learning）和单样本学习（One-shot Learning）&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;零样本学习：基于可见标注数据集&amp;amp;可见标签集合（seen），学习并预测不可见（unseen，无标注）数据集结果。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;411--前景背景分割&quot;&gt;4.11  前景背景分割&lt;/h4&gt;

&lt;h4 id=&quot;412--工业相机ccd和cmos&quot;&gt;4.12  工业相机CCD和CMOS&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;CCD（电荷耦合元件）：输出节点统一输出数据，信号一致性好；CCD采用逐个光敏输出，速度较慢&lt;/li&gt;
  &lt;li&gt;CMOS（金属氧化物半导体元件）：CMOS芯片中每个像素都有自己的信号放大器，各自进行电荷到电压的转换，输出信号的一致性较差，比CCD的信号噪声更多。CMOS每个电荷元件都有独立的装换控制器，读出速度很快，FPS在500以上的高速相机大部分使用的都是CMOS。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;五-深度学习&quot;&gt;五. 深度学习&lt;/h3&gt;
&lt;h4 id=&quot;51--梯度消失的原因和解决办法有哪些&quot;&gt;5.1  梯度消失的原因和解决办法有哪些？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;梯度消失：每一层非线性层都可以视为是一个非线性函数 f(x)f(x)(非线性来自于非线性激活函数），因此整个深度网络可以视为是一个复合的非线性多元函数。那么根据“链式求导”法则，比如rnn来说，其激活函数为tanh，那么tanh的导数的最大值是1，那么如果连乘0.8的100次方，无线接近于0，导致梯度消失。&lt;/li&gt;
  &lt;li&gt;梯度爆炸：tanh导数 * W权重，这里如果W的值太大了，随着序列长度的增加，连乘无限大，导致梯度爆炸。&lt;/li&gt;
  &lt;li&gt;解决方案：一个是激活函数比如relu系列，一个初始化权重 ，一个是梯度裁剪&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;52--rnn-和lstm的差别在哪&quot;&gt;5.2  RNN 和LSTM的差别在哪？&lt;/h4&gt;

&lt;p&gt;RNN的前向推导公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giw0543q2gj30ep07bq34.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;LSTM的三种门控制如下：
&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giw15g44kej311m0migvc.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上图所示，它们的名字、表示的计算过程及输出分别是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/007S8ZIlgy1giw16ne833j30is04ygm9.jpg&quot; alt=&quot;&quot; /&gt;
可以看到，除了参数不同，它们计算公式是一样的。啰嗦一句，上图中 [公式] 表示sigmoid函数， [公式] 表示tanh函数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;RNN来说，它能够处理一定的短期依赖，但无法处理长期依赖问题。原因：当序列较长时，序列后部的梯度很难反向传播到前面的序列，比如10个元素以前，这就产生了梯度消失问题&lt;/li&gt;
  &lt;li&gt;当然，RNN也存在梯度爆炸问题，但这个问题一般可以通过梯度裁剪（gradient clipping）来解决&lt;/li&gt;
  &lt;li&gt;RNN没有细胞状态；LSTM通过细胞状态记忆信息。&lt;/li&gt;
  &lt;li&gt;RNN激活函数只有tanh；LSTM通过输入门、遗忘门、输出门引入sigmoid函数并结合tanh函数，添加求和操作，减少梯度消失和梯度爆炸的可能性。&lt;/li&gt;
  &lt;li&gt;RNN只能够处理短期依赖问题；LSTM既能够处理短期依赖问题，又能够处理长期依赖问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;53--注意力机制是为了解决什么问题为什么选用了双向循环神经网络&quot;&gt;5.3  注意力机制是为了解决什么问题？为什么选用了双向循环神经网络？&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;人脑在工作时具有一定注意力，当欣赏艺术品时，既可以看到全貌，也可以关注 细节，眼睛聚焦在局部，忽略其他位置信息。说明人脑在处理信息的时候有一定权重划分。而注意力机制的提出正是模仿了人脑的这种核心特性。&lt;/li&gt;
  &lt;li&gt;实际使用中，随着输入序列长度的增加，模型性能显著下降。因为&lt;strong&gt;编码时输入序列的全部信息被压缩到一个向量表示中去&lt;/strong&gt;。&lt;strong&gt;序列越长，句子越前面的词的信息丢失就越严重&lt;/strong&gt;。以100词的句子为例，编码时将整个句子的信息压缩到一个向量中去，而在解码时(比如翻译)，目标语言第一个单词大概率与源语言第一个单词对应，这就意味着第一步的解码需要考虑到100步之前的信息。一个小技巧是可以将&lt;strong&gt;源语言句子逆向输入&lt;/strong&gt;，或者重复输入两遍，得到一定的提升，也可以使用&lt;strong&gt;LSTM&lt;/strong&gt;缓解这个问题。但对于&lt;strong&gt;过长序列仍难以有很好表现&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;54--batch-normalization和dropout差别&quot;&gt;5.4  Batch Normalization和Dropout差别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;BN训练和测试时的参数是一样的嘛？&lt;/strong&gt;BN是对每一批训练数据进行归一化，使用每一批数据的均值和方差；测试的时候，每一批数据中仅有一个样本，没有batch概念了，这里的均值和方差就是全量数据均值和方差。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;BN训练时为什么不用全量训练集的均值和方差呢？&lt;/strong&gt;对于BN，是对每一批数据进行归一化到一个相同的分布，而每一批数据的均值和方差会有一定的差别，而不是用固定的值，这个差别实际上也能够增加模型的鲁棒性，也会在一定程度上减少过拟合。&lt;strong&gt;BN操作把分布压缩在[-1,1],服从均值为0,方差为1的正太分布&lt;/strong&gt;，相当于把大部分Activation的值落入非线性函数的线性区内，其对应的导数远离导数饱和区，这样来加速训练收敛过程。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dropout的作用是什么？&lt;/strong&gt; 在训练的过程中以一定概率使得神经元失活，即输出为0，以提高模型的泛化能力，减少过拟合。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dropout 在训练和测试时都需要嘛？&lt;/strong&gt;dropout仅在训练的时候采用，为了减少神经元对部分上层神经元的依赖，类似于将多个不同的网络结构的模型集成起来，减少过拟合和增强其鲁棒性。测试的时候用到的是整个训练完成的模型，不需要dropout。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dropout 如何平衡训练和测试时的差异呢？&lt;/strong&gt;假设失活概率为 p ，就是这一层中的每个神经元都有p的概率失活，如下图的三层网络结构中，如果失活概率为0.5，则平均每一次训练有3个神经元失活，所以输出层每个神经元只有3个输入，而实际测试时是不会有dropout的，输出层每个神经元都有6个输入，这样在训练和测试时，输出层每个神经元的输入和的期望会有量级上的差异。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BN和Dropout共同使用时会出现的问题&lt;/strong&gt;BN和Dropout单独使用都能减少过拟合并加速训练速度，但如果一起使用的话并不会产生1+1&amp;gt;2的效果，相反可能会得到比单独使用更差的效果。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;55--batch-normalization和layer-normalization的差别&quot;&gt;5.5  Batch Normalization和Layer Normalization的差别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;LN和BN都是一种归一化方式，差别是：BN是取的是不同样本的同一个特征进行归一化；LN取得是同一个样本的不同特征。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;应用场景不同：LN适用于RNN或者batchsize较小；BN适用于CNN。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对于RNN来说，每个样本的长度都是不同的，那么当BN需要统计靠后的时间片段的时候，可能都没有这方面的信息，那么只基于某些长时间片段的样本的统计信息无法反应出全局分布，所以就不合适了。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;56--bert的具体网络结构以及训练过程及其优势在哪&quot;&gt;5.6  bert的具体网络结构，以及训练过程，及其优势在哪&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;bert处理句子是整体处理的，不是逐字处理的，解决了不受长期依赖问题困扰的主要原因（不存在过去信息丢失的风险），同时提高了训练效率。&lt;/li&gt;
  &lt;li&gt;多头注意力和位置嵌入：提供了有关不同单词之间的关系信息。&lt;/li&gt;
  &lt;li&gt;总结：完全避免了递归操作，通过整体处理句子以及学习单词之间的关系来感谢多头注意机制和位置嵌入。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;57--albert和bert的差别在哪&quot;&gt;5.7  albert和bert的差别在哪&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;albert的核心：&lt;strong&gt;训练出更小但效果更好的模型!&lt;/strong&gt; 想让模型更轻，训练更快，效果更好！（期望的是&lt;strong&gt;用更少量的数据，得到更好的结果&lt;/strong&gt;）。ALBERT提出了三种优化策略，做到了比BERT模型小很多的模型，但效果反而超越了BERT， XLNet。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Factorized Embedding Parameterization&lt;/strong&gt;. 他们做的第一个改进是针对于Vocabulary Embedding。在BERT、XLNet中，词表的embedding size(E)和transformer层的hidden size(H)是等同的，所以E=H。但实际上词库的大小一般都很大，这就导致模型参数个数就会变得很大。为了解决这些问题他们提出了一个基于factorization的方法。他们没有直接把one-hot映射到hidden layer, 而是先把one-hot映射到低维空间之后，再映射到hidden layer。这其实类似于做了矩阵的分解。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Cross-layer parameter sharing&lt;/strong&gt;. 每一层的layer可以共享参数，这样一来参数的个数不会以层数的增加而增加。所以最后得出来的模型相比BERT-large小18倍以上。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Inter-sentence coherence loss&lt;/strong&gt;. 在BERT的训练中提出了next sentence prediction loss, 也就是给定两个sentence segments, 然后让BERT去预测它俩之间的先后顺序，但在ALBERT文章里提出这种是有问题的，其实也说明这种训练方式用处不是很大。 所以他们做出了改进，他们使用的是setence-order prediction loss (SOP)，其实是基于主题的关联去预测是否两个句子调换了顺序。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;58--cnn和rnn的差别&quot;&gt;5.8  CNN和RNN的差别&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;训练速度上：CNN快很多。RNN慢的原因是每个timestep的计算，都要依赖前一个时刻的输出。而cnn的卷积的时候，和空间上其他的点没有任何联系，适合并行计算。&lt;/li&gt;
  &lt;li&gt;数据约束：CNN对于数据的约束就很强了，图像识别，input的纬度是48*48的，必须定死了，而RNN其实对于数据的长度（句子的长度）没有要求（TF里面有动态rnn来在输入rnn之前去掉pad为0的地方）&lt;/li&gt;
  &lt;li&gt;卷积层不同空间位置的神经元共享权值，用于发现图像中不同空间位置的模式。共享参数是深度学习一个重要的思想，其在减少网络参数的同时仍然能保持很高的网络容量(capacity)。卷积层在空间方向共享参数，而循环神经网络(recurrent neural networks)在时间方向共享参数。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;59--深度学习平台&quot;&gt;5.9  深度学习平台&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;阿里NASA计划的机器学习平台PAI（17年）
    &lt;ul&gt;
      &lt;li&gt;全面兼容TF，Caffe，MXNet深度学习框架&lt;/li&gt;
      &lt;li&gt;提供云端的计算资源&lt;/li&gt;
      &lt;li&gt;集成很多机器学习算法（分类，回归，聚类）&lt;/li&gt;
      &lt;li&gt;支持大规模的分布式数据训练&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;百度paddlepaddle飞桨(18年)
    &lt;ul&gt;
      &lt;li&gt;支持大规模的分布式数据训练&lt;/li&gt;
      &lt;li&gt;多平台部署&lt;/li&gt;
      &lt;li&gt;产业级的开源模型库（语义理解，图像分类，目标检测，图像分割等多种场景）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;微软Microsoft Custom Vision Services（17年）
    &lt;ul&gt;
      &lt;li&gt;针对的是图像分类器&lt;/li&gt;
      &lt;li&gt;提供迁移学习的模型&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;谷歌的Cloud AutoML
    &lt;ul&gt;
      &lt;li&gt;针对的是图像分类器&lt;/li&gt;
      &lt;li&gt;提供迁移学习的模型&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="deeplearning" />
      
        <category term="machinelearning" />
      

      
        <summary type="html">面试中机器学习中常问的问题总结</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">深度学习调参经验总结</title>
      <link href="http://localhost:4000/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E6%80%BB%E7%BB%93" rel="alternate" type="text/html" title="深度学习调参经验总结" />
      <published>2019-03-09T18:20:00+08:00</published>
      <updated>2019-03-09T18:20:00+08:00</updated>
      <id>http://localhost:4000/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E6%80%BB%E7%BB%93</id>
      <content type="html" xml:base="http://localhost:4000/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%B0%83%E5%8F%82%E6%80%BB%E7%BB%93">&lt;h3 id=&quot;一-网络中loss表现过于震荡&quot;&gt;一. 网络中loss表现过于震荡&lt;/h3&gt;
&lt;h4 id=&quot;11--模型拟合能力不够导致模型震荡&quot;&gt;1.1  模型拟合能力不够导致模型震荡&lt;/h4&gt;
&lt;p&gt;model（层数：input(30,300,3) ==&amp;gt; ful_collected_layer(30,300,64) ==&amp;gt; lstm ==&amp;gt; ful_collected_layer ==&amp;gt; output）此时模型的loss由1到192震动太大，acc也是在一个epoch中时好时坏，由此考虑到是模型的分类能力的问题（可能处理不了非线性或者是异或的问题）&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;增加了一层全连接层，之后效果显著，模型虽然也存在loss和acc会有极小幅度的震荡，但是趋向于收敛&quot;&quot;&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ful_collected_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ful_collected_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ful_collected_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;12-batch-size-设置过小导致模型震荡&quot;&gt;1.2 batch size 设置过小导致模型震荡&lt;/h4&gt;
&lt;p&gt;之前模型用的是batch_size = 30，经过增大batch_size之后，模型的震荡程度也减小。这里如果GPU显存小的情况下，只能将batch设置小。&lt;/p&gt;

&lt;h4 id=&quot;13-输入模型的数据没有shuffle导致模型震荡&quot;&gt;1.3 输入模型的数据没有shuffle导致模型震荡&lt;/h4&gt;
&lt;p&gt;之前数据没有进行shuffle，导致在某一个batch_size中学习到的全是正样本，某一个batch_size里面又全是负样本，shuffle之后，振荡减小。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;110&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 设定种子数，不然下面shuffle之后的y无法与X对应上&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;110&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;二-网络经过多轮迭代依然无法上升了acc始终在79&quot;&gt;二. 网络经过多轮迭代依然无法上升了，acc始终在79%&lt;/h3&gt;
&lt;h4 id=&quot;21-增大学习率&quot;&gt;2.1 增大学习率&lt;/h4&gt;
&lt;p&gt;开始学习率设置的是learning_rate = 0.001,之后增大10倍，设置为learning_rate = 0.01之后，acc在70多轮的时候就能提升到90% ，300轮之后能到97%。&lt;/p&gt;

&lt;p&gt;理由：当我们把学习率设置较小的时候，那么梯度下降的时候迈的步子就小，可能在遇到大的坑的时候就出去，然后就一致在坑里徘徊，最终只能达到局部最优，无法达到全局最优，调参的过程中应该首先实验大的学习率，然后再依次减小实验。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;22-优化器的选择&quot;&gt;2.2 优化器的选择&lt;/h4&gt;
&lt;p&gt;实验下其他的梯度下降的优化器（optimizer），比如Adam，SGD，Adadelta，RMSProp，Momentum等，一般来说Adam较快，SGD最慢，但是却是最准确和稳定的，因此可以先用Adam进行实验，最后用SGD进行调参。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tf.train.AdadeltaOptimizer&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.001, &lt;span class=&quot;nv&quot;&gt;rho&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.95, &lt;span class=&quot;nv&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1e-08, &lt;span class=&quot;nv&quot;&gt;use_locking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;False, &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;’Adadelta’&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

tf.train.MomentumOptimizer&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;learning_rate, momentum, &lt;span class=&quot;nv&quot;&gt;use_locking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;False, &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;’Momentum’, &lt;span class=&quot;nv&quot;&gt;use_nesterov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;False&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

tf.train.AdamOptimizer&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.001, &lt;span class=&quot;nv&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.9, &lt;span class=&quot;nv&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.999, &lt;span class=&quot;nv&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1e-08, &lt;span class=&quot;nv&quot;&gt;use_locking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;False, &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;’Adam’&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

tf.train.GradientDescentOptimizer&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;learning_rate, &lt;span class=&quot;nv&quot;&gt;use_locking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;False,name&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;’GradientDescent’&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;三-遇到loss和weights在训练中全是nan值的情况&quot;&gt;三. 遇到loss和weights在训练中全是nan值的情况&lt;/h3&gt;
&lt;h4 id=&quot;31-查看输入数据中是否存在nan值&quot;&gt;3.1 查看输入数据中是否存在nan值&lt;/h4&gt;
&lt;p&gt;检查自己做完预处理的数据，看下是否存在nan值（比如需要计算0/0和log0的情况）&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;检验下input_data中是否存在nan值&quot;&quot;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 这里的input_data 是三维数组必须转成2d&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;input_data_pd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data_pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isnull&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;input data has nan value!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;list_nan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argwhere&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isnan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data_pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_nan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;32-梯度爆炸或者是梯度消失&quot;&gt;3.2 梯度爆炸或者是梯度消失&lt;/h4&gt;
&lt;p&gt;可能是&lt;strong&gt;梯度爆炸&lt;/strong&gt;，有以下解决方式&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;（1）预训练+微调&lt;/li&gt;
  &lt;li&gt;（2）梯度剪切 + 权重正则&lt;/li&gt;
  &lt;li&gt;（3）使用不同的激活函数，比如之前用relu，可以换成tanh或者是elu&lt;/li&gt;
  &lt;li&gt;（4）使用batchnorm&lt;/li&gt;
  &lt;li&gt;（5）使用LSTM网络（如果之前用的是RNN结构）&lt;/li&gt;
  &lt;li&gt;（6）使用残差结构&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下是几种在不改变模型层数和结构的情况下解决梯度爆炸和梯度消失的方案。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&quot;权重L2正则化&quot;&quot;&quot;&lt;/span&gt;
cross_entropy &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-tf&lt;/span&gt;.reduce_sum&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;ys &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; 	tf.log&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;tf.clip_by_value&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;tf.nn.softmax&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;prediction&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, 1e-10, 1.0&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
weights_lossL2 &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.add&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;tf.nn.l2_loss&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;weights_in&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,tf.nn.l2_loss&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;weights_out&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; 0.01
regularzation_loss &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; cross_entropy + weights_lossL2
cost &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.reduce_mean&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;regularzation_loss&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&quot;梯度剪裁&quot;&quot;&quot;&lt;/span&gt;
opt &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.train.MomentumOptimizer&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.001, &lt;span class=&quot;nv&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0.5&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Compute the gradients for a list of variables.&lt;/span&gt;
grads_and_vars &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; opt.compute_gradients&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;cross_entropy, 	 tf.trainable_variables&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# grads_and_vars is a list of tuples (gradient, variable).  Do whatever you&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# need to the 'gradient' part, for example cap them, etc.&lt;/span&gt;
capped_grads_and_vars &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;tf.clip_by_value&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;gv[0], 0.1, 5.&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;, gv[1]&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;gv &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;grads_and_vars]
&lt;span class=&quot;c&quot;&gt;# Ask the optimizer to apply the capped gradients.&lt;/span&gt;
optimizer &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; opt.apply_gradients&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;capped_grads_and_vars&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;33-使用了梯度参见和l2正则之后出现loss增大的情况&quot;&gt;3.3 使用了&lt;strong&gt;梯度参见和L2正则&lt;/strong&gt;之后出现&lt;strong&gt;Loss增大&lt;/strong&gt;的情况&lt;/h4&gt;
&lt;p&gt;在使用了梯度裁剪之后，其实只是人为的控制梯度的变化（将weights控制在小范围内(0.1,5)之间），此时权重依旧可以通过BP算法向负梯度的方向前进，但是由于人为的控制，导致weight的梯度极有可能朝着正梯度方向进行，这就会导致可以更新权重，但是loss反而增大的原因。&lt;/p&gt;

&lt;h4 id=&quot;34-这里必须要修改模型结构&quot;&gt;3.4 这里必须要&lt;strong&gt;修改模型结构&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;举一个例子：利用4层全连接层作为一个分类器，来训练。经历过以上所有的方式（包括调整激活函数等），依旧无法使得模型的loss减少，当我将层数降低为3层的时候，模型loss开始收敛，那么这就说明当无法使得模型收敛的时候，其实极有可能是模型的结构问题，需要重新设计模型的结构层数。&lt;/p&gt;

&lt;h3 id=&quot;四训练中模型loss不收敛的几种情况&quot;&gt;四.训练中模型loss不收敛的几种情况&lt;/h3&gt;
&lt;p&gt;总结：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;train loss 不断下降，val loss不断下降 ==&amp;gt; 说明网络仍在学习&lt;/li&gt;
  &lt;li&gt;train loss 不断下降，val loss趋于不变 ==&amp;gt; 说明网络过拟合&lt;/li&gt;
  &lt;li&gt;train loss 趋于不变，val loss不断下降 ==&amp;gt; 说明数据集100%有问题&lt;/li&gt;
  &lt;li&gt;train loss 趋于不变，val loss趋于不变 ==&amp;gt; 说明学习遇到瓶颈，需要减小学习率或批量数目&lt;/li&gt;
  &lt;li&gt;train loss 不断上升，val loss不断上升 ==&amp;gt; 说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题&lt;/li&gt;
  &lt;li&gt;train loss 到稳定的时候反而比val loss还要高 ==&amp;gt; 测试集数据量太小了，误差计算算法有问题&lt;/li&gt;
  &lt;li&gt;train loss 和 val loss趋于不变，但是val loss趋于0，而train loss却还很高 ==&amp;gt; 说明使用dropout层后模型拟合能力变差，去掉dropout层。&lt;/li&gt;
  &lt;li&gt;train loss 和 val loss同时极缓的形式增大，这里可以考虑降低学习率或者是从这里进行截断，以loss最低点作为模型最优点。&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      <author>
          <name></name>
        
        
      </author>

      

      
        <category term="deeplearning" />
      

      
        <summary type="html">讲述在深度学习建模过程中遇到的问题及其解决思路</summary>
      

      
      
    </entry>
  
</feed>
