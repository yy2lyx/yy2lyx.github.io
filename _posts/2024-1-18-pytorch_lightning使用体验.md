---
layout: post
current: post
cover: assets/images/lightning.jpg
navigation: True
title: pytorch_lightningä½¿ç”¨ä½“éªŒ
date: 2023-12-28 00:00:00
tags: [DeepLearning]
excerpt: è®°å½•pytorch_lightningçš„ä½¿ç”¨è¿‡ç¨‹å¿ƒå¾—ä½“ä¼š
class: post-template
subclass: 'post'
---



> å¦‚æœæ˜¯ä¸€äº›å°æ¨¡å‹æƒ³è¦å¿«é€Ÿå®éªŒï¼Œä¸æƒ³æ€ä¹ˆå†™ä»£ç çš„ï¼Œå¯ä»¥é€šè¿‡pytorch_lightningå¿«é€Ÿæ­å»ºæ¨¡å‹ï¼Œä½†æ˜¯å¦‚æœæ¶‰åŠåˆ°å¤§æ¨¡å‹ï¼Œä»¥åŠåˆ†å¸ƒå¼è®­ç»ƒé¢„æµ‹ï¼Œå’±è¿˜æ˜¯è€è€å®å®ç”¨pytorchå§ã€‚

### ä¸€. ä½¿ç”¨ä½“éªŒ

å°±åƒå¾ˆå¤šå¹´å‰å†™è¿‡tensorflowä¹‹åçœ‹åˆ°kerasåçš„æ¬£å–œï¼Œå½“æˆ‘çœ‹åˆ°pytorch_lightningåç¬é—´å°±å–œæ¬¢ä¸Šäº†å®ƒï¼å¯¹äºpytorchçš„é‡åº¦ä½¿ç”¨è€…æ¥è¯´ï¼Œæ¯æ¬¡éƒ½è¦å†™å¾ˆå¤šé‡å¤çš„è®­ç»ƒé¢„æµ‹ä»£ç ï¼Œæ€»æ„Ÿè§‰ä»£ç å¤ç”¨èµ·æ¥å¾ˆéº»çƒ¦ï¼Œäºæ˜¯pytorch_lightningå®ƒæ¥å•¦ï¼

**pytorch_lightningçš„ä¼˜åŠ¿ï¼š**

* ä»£ç å¯è¯»æ€§ã€å¤ç”¨æ€§é«˜

* è‡ªç”±åº¦å’Œpytorchä¸€æ ·é«˜ï¼Œå¹¶æ²¡æœ‰åƒä½¿ç”¨kerasä¸€æ ·æ„Ÿè§‰å°è£…è¿‡æ­»çš„æ„Ÿè§‰ã€‚

* èƒ½åƒkerasä¸€æ ·å¿«é€Ÿæ­å»ºæ¨¡å‹ï¼Œç®€åŒ–æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹çš„è¿‡ç¨‹

* æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ

### äºŒ. å®‰è£…å’Œä½¿ç”¨

å®˜ç½‘åœ°å€æ˜¯ï¼šhttps://lightning.ai/ 

pipè¿›è¡Œå®‰è£…ï¼š`pip show pytorch_lightning`

ä¸‹é¢ä½¿ç”¨MNISTæ¥å±•ç¤ºå¦‚ä½•ä½¿ç”¨pytorch_lightningæ¥ç®€åŒ–è‡ªå·±çš„ä»£ç 

#### 2.1 æ•°æ®æ¨¡å—LightningDataModule

é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›é¢„å¤„ç†ï¼Œä»¥åŠåœ¨å®šä¹‰å®Œè‡ªå·±çš„datasetåï¼Œéœ€è¦å®šä¹‰dataloaderï¼Œè¿™é‡Œå¯ä»¥ç›´æ¥ç»§æ‰¿LightningDataModuleæ¨¡å—ï¼Œç›´æ¥é‡å†™å…¶ä¸­çš„æ–¹æ³•å³å¯ã€‚

```python
class MNISTDataModule(LightningDataModule):
    def __init__(self,root_dir,val_size,num_workers,batch_size):
        super(MNISTDataModule, self).__init__()
        self.save_hyperparameters()

    def prepare_data(self):
        """
        download data once
        """
        MNIST(self.hparams.root_dir, train=True, download=True)
        MNIST(self.hparams.root_dir, train=False, download=True)

    def setup(self, stage=None):
        """
        setup dataset for each machine
        """
        dataset = MNIST(self.hparams.root_dir,
                        train=True,
                        download=False,
                        transform=T.ToTensor())
        train_length = len(dataset)
        self.train_dataset, self.val_dataset = \
            random_split(dataset,
                         [train_length - self.hparams.val_size, self.hparams.val_size])

    def train_dataloader(self):
        return DataLoader(self.train_dataset,
                          shuffle=True,
                          num_workers=self.hparams.num_workers,
                          batch_size=self.hparams.batch_size,
                          pin_memory=True)

    def val_dataloader(self):
        return DataLoader(self.val_dataset,
                          shuffle=False,
                          num_workers=self.hparams.num_workers,
                          batch_size=self.hparams.batch_size,
                          pin_memory=True)
```

#### 2.2 è®­ç»ƒå’Œé¢„æµ‹æ¨¡å—LightningModule

ä¹‹å‰æ¯æ¬¡è®­ç»ƒå’Œé¢„æµ‹æ¨¡å‹çš„æ—¶å€™ï¼Œæˆ‘éƒ½ä¼šå†™ä¸€ä¸ªè¯¥è¿‡ç¨‹çš„ä¸€ä¸ªåŸºç±»ï¼Œæ¥å°è£…æ¯ä¸ªepochæ¨¡å‹è®­ç»ƒã€éªŒè¯çš„è¿‡ç¨‹ï¼Œå…¶å®æ¯æ¬¡ä¸åŒçš„é¡¹ç›®ã€ä¸åŒçš„æ¨¡å‹ç»§æ‰¿äº†ä¸Šè¿°çš„åŸºç±»ï¼Œä½†æ˜¯åŸºæœ¬ä¸Šä¹Ÿå°±æ˜¯æ”¹å˜å…¶ä¸­çš„æ¯ä¸ªbatchè®­ç»ƒã€éªŒè¯çš„æ–¹æ³•ï¼Œç„¶åçœ‹åˆ°äº†ä¸€ä¸ªåˆ«äººå°è£…çš„è¿™ä¹ˆå®Œç¾çš„è®­ç»ƒé¢„æµ‹åŸºç±»ï¼Œç®€ç›´å¼€å¿ƒçš„ä¸è¦ä¸è¦çš„ã€‚ã€‚

```python
class MNISTModel(LightningModule):
    def __init__(self, hidden_dim, num_classes, lr, num_epochs):
        super().__init__()
        self.save_hyperparameters()
        self.net = LinearModel(self.hparams.hidden_dim)
        self.training_step_outputs = []
        self.validation_step_outputs = []

        self.loss_fn = nn.CrossEntropyLoss()
        self.accuracy = torchmetrics.Accuracy(
            task="multiclass", num_classes=self.hparams.num_classes
        )
        self.f1_score = torchmetrics.F1Score(task="multiclass", num_classes=self.hparams.num_classes)

    def forward(self, x):
        return self.net(x)

    def configure_optimizers(self):
        self.optimizer = Adam(self.net.parameters(), lr=self.hparams.lr)
        scheduler = CosineAnnealingLR(self.optimizer,
                                      T_max=self.hparams.num_epochs,
                                      eta_min=self.hparams.lr / 1e2)

        return [self.optimizer], [scheduler]

    def lr_scheduler_step(self, scheduler, *args, **kwargs):
        scheduler.step()

    def _common_step(self, batch, batch_idx):
        images, labels = batch
        logits_predicted = self(images)

        loss = self.loss_fn(logits_predicted, labels)
        acc = self.accuracy(logits_predicted, labels)
        # acc = torch.sum(torch.eq(torch.argmax(logits_predicted, -1), labels).to(torch.float32)) / len(labels)
        return loss, acc

    def training_step(self, batch, batch_idx):
        loss, acc = self._common_step(batch,batch_idx)

        self.log('lr', get_learning_rate(self.optimizer))
        self.log('train_step_loss', loss)

        train_rs = {'train_loss': loss,
               'train_acc': acc}
        self.training_step_outputs.append(train_rs)
        return loss

    def predict_step(self, batch, batch_idx: int, dataloader_idx: int = 0):
        rs = self(batch[0])
        rs = torch.argmax(rs, -1).numpy().tolist()
        return rs

    def validation_step(self, batch, batch_idx):
        loss, acc = self._common_step(batch, batch_idx)

        log = {'val_loss': loss,
               'val_acc': acc}
        self.validation_step_outputs.append(log)
        return log
```

#### 2.3 callbacks

è¿™é‡Œå¦‚æœæˆ‘ä»¬è§‰å¾—ä¸Šé¢è¿™äº›æ— æ³•æ»¡è¶³æˆ‘ä»¬çš„æ—¥å¸¸è®­ç»ƒã€é¢„æµ‹çš„éœ€æ±‚ï¼Œé‚£ä¹ˆå®Œå…¨å¯ä»¥å†å¢åŠ ä¸€äº›å…¶ä»–éœ€è¦çš„ç¬¬ä¸‰æ–¹å’Œè‡ªå·±å®šä¹‰çš„callbacksï¼Œå½“ç„¶pytorch_lightningå…¶å®å·²ç»å°è£…äº†å¾ˆå¤šå¸¸ç”¨çš„callbacksäº†ï¼Œæ¯”å¦‚ä¸‹é¢çš„å‡ ä¸ªå¸¸ç”¨çš„ï¼š

* æ¨¡å‹å®šä¹‰æ€ä¹ˆä¿å­˜ckptï¼š`ModelCheckpoint`

* å¦‚ä½•å®šä¹‰è®­ç»ƒåŠæ—©åœæ­¢ï¼š`MINISTCallBack`

* å®šä¹‰è¿›åº¦æ¡ï¼š`TQDMProgressBar`

å½“ç„¶äº†ï¼Œæˆ‘ä»¬æƒ³å®šä¹‰å±äºè‡ªå·±çš„callbackæ€ä¹ˆå¼„å‘¢ï¼š

```python
class MINISTCallBack(Callback):
    def __init__(self):
        super(MINISTCallBack, self).__init__()


    def on_predict_end(self, trainer: "pl.Trainer", pl_module: "pl.LightningModule"):
        print("Predict is ending")

    def on_train_epoch_end(self, trainer : "pl.Trainer", pl_module: "pl.LightningModule"):
        epoch_mean_loss = torch.stack([x['train_loss'] for x in pl_module.training_step_outputs]).mean()
        epoch_mean_acc = torch.stack([x['train_acc'] for x in pl_module.training_step_outputs]).mean()
        pl_module.log("train/loss", epoch_mean_loss, prog_bar=True)
        pl_module.log("train/acc", epoch_mean_acc, prog_bar=True)

        pl_module.training_step_outputs.clear()

    def on_validation_epoch_end(self, trainer: "pl.Trainer", pl_module: "pl.LightningModule"):
        epoch_mean_loss = torch.stack([x['val_loss'] for x in pl_module.validation_step_outputs]).mean()
        epoch_mean_acc = torch.stack([x['val_acc'] for x in pl_module.validation_step_outputs]).mean()

        pl_module.log('val/loss', epoch_mean_loss, prog_bar=True)
        pl_module.log('val/acc', epoch_mean_acc, prog_bar=True)

        pl_module.validation_step_outputs.clear()
```

#### 2.4 è°ƒç”¨

å½“æˆ‘ä»¬éƒ½å†™å®Œäº†ä¸Šè¿°æˆ‘ä»¬å®šä¹‰å¥½çš„æ•°æ®æ¨¡å—ï¼Œè®­ç»ƒé¢„æµ‹æ¨¡å—ï¼Œé‚£ä¹ˆå¦‚ä½•ä½¿ç”¨å‘¢ï¼Ÿpytorch_lightningè¿™é‡Œç”¨äº†ä¸€ä¸ªä¸“é—¨çš„ç±»Traineræ¥è°ƒç”¨ã€‚

**è®­ç»ƒè°ƒç”¨**ï¼š

```python
trainer = Trainer(max_epochs=config.num_epochs,
                      # resume_from_checkpoint = 'ckpts/exp3/epoch=7.ckpt', # æ–­ç‚¹ç»­è®­
                      callbacks=callbacks,
                      logger=logger,
                      enable_model_summary=True,  # æ˜¾ç¤ºæ¨¡å‹æ„é€ 
                      accelerator='auto',
                      devices=1,  # å¤šå°‘ä¸ªè®¾å¤‡
                      deterministic=True,
                      num_sanity_val_steps=1,  # æ­£å¼è®­ç»ƒä¹‹å‰è·‘ä¸€æ¬¡validation æµ‹è¯•ç¨‹åºæ˜¯å¦å‡ºé”™
                      benchmark=True,  # cudnnåŠ é€Ÿè®­ç»ƒï¼ˆè¦ç¡®ä¿æ¯ä¸ªbatchåŒä¸€ä¸ªå¤§å°ï¼‰
                      )
    # mnist_model.load_from_checkpoint('ckpts/exp3/epoch=7.ckpt')
    trainer.fit(mnist_model,mnist_data)
```

**é¢„æµ‹è°ƒç”¨**ï¼Œå¯ä»¥å®šä¹‰ä¸€ä¸ªdataloaderï¼Œä¹Ÿå¯ä»¥å®šä¹‰æµ‹è¯•çš„æ•°æ®æ¨¡å—ï¼ŒåŒæ—¶ä¹Ÿèƒ½ç›´æ¥å¯¹å•ä¸€ä¸€ä¸ªtensorä½œä¸ºè¾“å…¥ï¼Œè¿›è¡Œé¢„æµ‹ï¼š

```python
rs = trainer.predict(mnist_model, dataloaders=test_loader)
rs = trainer.predict(mnist_model, datamodule=test_datamodule)
```

### ä¸‰. åˆ†å¸ƒå¼è®­ç»ƒ

pytorch_lightningä¹Ÿæ”¯æŒåˆ†å¸ƒå¼ï¼Œä½†æ˜¯å®ƒåªæ”¯æŒpytorchåŸç”Ÿçš„DDPï¼Œä½œä¸ºè¢«HuggingFaceçš„accelerateåœˆç²‰çš„æˆ‘ã€‚ã€‚ã€‚åªèƒ½é€€å‘äº†ï¼Œæ‹œæ‹œğŸ‘‹ğŸ»
